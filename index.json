[
{
	"uri": "https://linuxias.github.io/linux/",
	"title": "1. Linux",
	"tags": [],
	"description": "",
	"content": "1. Linux The chapter that organizes information about Linux.\n"
},
{
	"uri": "https://linuxias.github.io/container/",
	"title": "2. Container",
	"tags": [],
	"description": "",
	"content": "2. Container Namespace, Cgroup\n"
},
{
	"uri": "https://linuxias.github.io/machinelearning/",
	"title": "Machine Learning",
	"tags": [],
	"description": "",
	"content": "Machine Leanrning "
},
{
	"uri": "https://linuxias.github.io/books/",
	"title": "Books",
	"tags": [],
	"description": "",
	"content": "Books This chapter is for reviewing books\n"
},
{
	"uri": "https://linuxias.github.io/container/cgroup/",
	"title": "Cgroup",
	"tags": [],
	"description": "",
	"content": "Cgroup "
},
{
	"uri": "https://linuxias.github.io/linux/compilelink/",
	"title": "Compile&amp;Link",
	"tags": [],
	"description": "",
	"content": "Compile \u0026amp; Link "
},
{
	"uri": "https://linuxias.github.io/container/namespace/",
	"title": "Namespace",
	"tags": [],
	"description": "",
	"content": "Namespace "
},
{
	"uri": "https://linuxias.github.io/container/cgroup/1.cgroup/",
	"title": "1. Cgroup",
	"tags": [],
	"description": "",
	"content": "cgroup은 단일 또는 태스크 단위의 프로세스 그룹에 대한 자원 할당을 제어하는 커널 모듈입니다. Cgroup은 Control group으로 처음 개발되었을 때는 group이 아니라 container란 용어를 사용했었습니다. 하지만 container란 용어는 너무 많은 의미를 내포하고 있다고 판단하여 지금의 group이만 이름으로 변경되었습니다.\n현재 cgroup은 v1와 v2 두가지 버전이 공존하고 있습니다. v1의 서비스시템 중 일부는 v2에 포함되어 있는 상태입니다. 언젠가 v2만 남겠죠..?\ncgroup 서브시스템 cgroup은 여러 개의 서브시스템으로 이루어져 있습니다. (아래 표에 모든 서브시스템을 작성한 것은 아니니, 유의해주세요.)\n   subsystem description     cpu cgroups는 시스템이 busy 상태일 때 CPU 공유를 최소화 즉 사용량을 제한 할 수 있습니다. 이 서브시스템은 CPU에 cgroup 작업 액세스를 제공하기 위한 스케줄러(Documentation/scheduler/sched-design-CFS.txt)를 제공합니다.   cpuacct 프로세스 그룹 별 CPU 자원 사용에 대한 분석 통계를 생성 및 제공합니다. (Documentation/cgroup-v1/cpuacct.txt)   cpuset 개별 CPU 및 메모리 노드를 cgroup에 바인딩 하기 위해 사용하는 서브시스템입니다(Documentation/cgroup-v1/cpusets.txt.)   memory cgroup 작업에 사용되는 메모리(프로세스, 커널, swap)를 제한하고 리포팅을 제공하는 서브시스템입니다. (Documentation/cgroup-v1/memory.txt)   blkio 특정 block device에 대한 접근을 제한하거나 제어하기 위한 서브시스템입니다. block device에 대한 IO 접근 제한을 설정할 수 있습니다. (Documentation/cgroup-v1/blkio-controller.txt)   devices cgroup의 작업 단위로 device에 대한 접근을 허용하거나 제한합니다. whitelist와 blacklist로 명시되어 있습니다. (Documentation/cgroup-v1/devices.txt.)   freezer cgroup의 작업을 일시적으로 정지(suspend)하거나 다시 시작(restore)할 수 있습니다. (Documentation/cgroup-v1/freezer-subsystem.txt.)   net_cls 특정 cgroup 작업에서 발생하는 패킷을 식별하기 위한 태그(classid)를 지정할 수 있습니다. 이 태그는 방화벽 규칙으로 사용되어 질 수 있습니다. (Documentation/cgroup-v1/net_cls.txt.)   net_prio cgroup 작업에서 생성되는 네트워크 트래픽의 우선순위를 선정할 수 있습니다. (Documentation/cgroup-v1/net_prio.txt.)   hugetlb HugeTLB에 대한 제한을 설정할 수 있습니다.   pid cgroup 작업에서 생성되는 프로세스의 수를 제한할 수 있습니다. (Documentation/cgroup-v1/pids.txt.)    cgroup은 가상 파일시스템의 디렉토리로 표시되는 계층 구조로 구성되어 집니다. 하지만 프로세스 계층구조와는 달리 다중 계층구조를 가집니다. 즉 하나의 계층 구조가 아닙니다.\ncgroup 사용방법 cgroup은 두 가지 방법으로 사용할 수 있습니다.\n cgroup 가상파일시스템을 마운트하여 파일 및 디렉토리를 조작하는 방법 사용자 도구 사용 (Debian, ubuntu는 cgroup-bin / RHEL, CentOS는 libcgroup)  cgroup의 실체는 파일시스템입니다. cgroup은 오직 프로세스(태스크) 들을 그룹화 하는 역할만 하며 내부적으로 자원을 제한하거나 할당하는 역할은 서브시스템에서 수행됩니다.\n참고자료  Containerization with LXC | Konstantin Ivanov [Linux] cgroup - (task) control group (1) (http://egloos.zum.com/studyfoss/v/5505982) [Linux] cgroup - (task) control group (1)(http://studyfoss.egloos.com/5506102) Docker(container)의 작동 원리: namespaces and cgroups(https://tech.ssut.me/what-even-is-a-container/) Control Groups | 문C 블로그(http://jake.dothome.co.kr/control-groups/) CGROUPS(7) linux manual page  "
},
{
	"uri": "https://linuxias.github.io/container/namespace/1.what_is_namespace/",
	"title": "1. Namespace",
	"tags": [],
	"description": "",
	"content": "Namespace 기술은 cgourp(Control Group)과 함께 컨테이너(Container) 솔루션을 구성하는 기술 중 하나입니다. 이번 글에서는 namespcae에 대해 정리한 후linux에서 제공하는 namespcae의 종류에 대해 정리하고자 합니다.\nnamespace는 전역 시스템 리소스를 추상화하여 전역 리소스의 자체 격리 인스턴스가있는 namespace 내의 프로세스에 표시 되도록합니다. 전역 리소스에 대한 변경은 namespace의 멤버, 즉 동일한 namespace를 가진 다른 프로세스에서 볼 수 있지만 다른 namespace를 가진 프로세스에서는 보이지 않습니다. namespcae를 사용하는 것은 컨테이너를 구현하는 것입니다.\n   Namespace Constant Isolates     IPC CLONE_NEWIPC System V IPC, POSIX message queues   Network CLONE_NEWNET Network devices, stacks, ports, etc.   Mount CLONE_NEWNS Mount points   PID CLONE_NEWPID Process IDs   User CLONE_NEWUSER User and group IDs   UTS CLONE_NEWUTS Hostname and NIS domain name    namespace API namespace API에는 아래의 시스템 콜과 함께 /proc 파일이 포함됩니다. 먼저 system call에 대해 설명드립니다.\n시스템 콜    API Description     setns(2) setns 시스템 콜은 호출하는 프로세스가 존재하는 namespace에 조인합니다. 조인하고자 하는 namespace는 /proc/[pid]/ns 디렉토리 아래 존재하는 하나의 namespace 파일디스크립터(fd) 를 이용합니다.   clone(2) clone(2) 시스템 콜은 새로운 프로세스를 생성합니다. 시스템 콜 호출 시 flags argument로 CLONE_NEW* flag를 하나 이상 전달합니다. CLONE_NEW* flag는 위에서 설명한 바 있습니다. 그럼 각 flag에 해당하는 새로운 namespace가 생성되며 그 namepsaces의 멤버로 자식 프로세스가 생성됩니다.   unshare(2) unshare() 시스템 콜을 호출한 프로세스를 새로운 namespace로 이동시킵니다. 만약 flags argutment가 CLONE_NEW* flag를 입력한다면, 새로운 namespace가 생성되고, 해당 namespace의 멤버로 이동합니다.    여기서 유의할 점은 clone(2) 와 unshare(2) 시스템 콜을 사용하여 새로운 namespace들을 생성하기 위해선 CAP_SYS_ADMIN capability가 필요합니다. user namespace 생성은 예외적으로 privilege가 필요하지 않습니다.\n/proc/[pid]/ns 디렉토리 그럼 /proc 파일시스템에서 namespace에 대해 간략히 정리하겠습니다. 모든 프로세스들은 /proc/[pid]/ns 디렉토리가 존재합니다. 아래 ns 디렉토리에 여러 namespace가 존재하는 것을 확인할 수 있습니다. 이 namespace는 setns(2) 시스템 콜을 이용해 namespace를 변경하고자 할 때 변경을 원하는 namespace의 fd로 사용됩니다.\n$ ls -l /proc/$$/ns total 0 lrwxrwxrwx. 1 mtk mtk 0 Jan 14 01:20 ipc -\u0026gt; ipc:[4026531839] lrwxrwxrwx. 1 mtk mtk 0 Jan 14 01:20 mnt -\u0026gt; mnt:[4026531840] lrwxrwxrwx. 1 mtk mtk 0 Jan 14 01:20 net -\u0026gt; net:[4026531956] lrwxrwxrwx. 1 mtk mtk 0 Jan 14 01:20 pid -\u0026gt; pid:[4026531836] lrwxrwxrwx. 1 mtk mtk 0 Jan 14 01:20 user -\u0026gt; user:[4026531837] lrwxrwxrwx. 1 mtk mtk 0 Jan 14 01:20 uts -\u0026gt; uts:[4026531838] 각 namespace 별 proc 파일은 다음과 같습니다.\n   namespace /proc file     IPC namespace /proc/[pid]/ns/ipc   Mount namespace /proc/[pid]/ns/mount   Network namespace /proc/[pid]/ns/net   PID namespace /proc/[pid]/ns/pid   User namespace /proc/[pid]/ns/user   uts namespace /proc/[pid]/ns/uts    Namespace 간략 정리 각 Namespace의 상세내용은 다른 글로 정리하고자 하며, 여기서는 간략하게 정리하고자 합니다.\nIPC namespace (CLONE_NEWIPC) IPC namespace는 특정 IPC 자원들(System V IPC,와 POSIX message queue)을 격리시킵니다. 특정 IPC 자원들의 공통적인 특징은 IPC 객체가 파일시스템 경로명 외의 메커니즘으로 식별된다는 것입니다. System V IPC에는 메시지 큐, 세마포어, 공유메모리를 가리킵니다.\nNetwork namespace (CLONE_NEWNET) Network namespace는 네트워크와 관련된 시스템 자원의 격리, 고립을 제공합니다. 해당되는 시스템 자원으로는 네트워크 디바이스들, IPv4, IPv6 프로토콜 스택, IP routing tables, 방화벽, /proc/net 디렉토리, /sys/class/net 디렉토리, 포트 번호 등등이 있습니다. 물리적 네트워크 장치는 정확히 하나의 네트워크 네임스페이스를 가질 수 있습니다. 가상 네트워크 장치는 네트워크 namespace 간에 터널을 생성하는데 사용할 수 있는 추상화된 파이프를 제공합니다.\nNetwork namespace가 해제되면, 물리 네트워크 장치는 초기 Network namespace로 변경됩니다. Network namespace를 사용하기 위해선 CONFIG_NET_NS 커널 옵션이 설정되어 있어야 합니다.\nMount namespaces (CLONE_NEWNS) Mount namespace는 파일시스템 마운트 지점의 집합을 고립, 격리합니다. 즉, 서로 다른 Mount namespace의 프로세스가 파일 시스템 구조에 대해 다른 뷰를 가질 수 있습니다. mount(2), umount(2) 를 이용해 Mount namespace 내에 마운트 집합들을 수정할 수 있습니다.\n/proc/[pid]/mounts 파일은 현재 프로세스의 Mount namespace에 마운트된 모든 파일시스템을 나열합니다. 이 파일의 포맷은 **fstab(5)**를 참고해주세요.\nseunghason@linuxias$cat /proc/self/mounts sysfs /sys sysfs rw,nosuid,nodev,noexec,relatime 0 0 proc /proc proc rw,nosuid,nodev,noexec,relatime 0 0 udev /dev devtmpfs rw,nosuid,relatime,size=16413672k,nr_inodes=4103418,mode=755 0 0 ... binfmt_misc /proc/sys/fs/binfmt_misc binfmt_misc rw,relatime 0 0 tmpfs /run/user/1000 tmpfs rw,nosuid,nodev,relatime,size=3288548k,mode=700,uid=1000,gid=1000 0 0 gvfsd-fuse /run/user/1000/gvfs fuse.gvfsd-fuse rw,nosuid,nodev,relatime,user_id=1000,group_id=1000 0 0 /proc/[pid]/mountstat 파일은 프로세스의 Mount namespace의 마운트 지점에 대한 정적, 설정 정보들을 보여줍니다. 보여지는 정보에 대한 것은 아래를 참고해주세요.\ndevice /dev/sda7 mounted on /home with fstype ext3 [statistics] ( 1 ) ( 2 ) (3 ) (4) The fields in each line are: (1) The name of the mounted device (or \u0026quot;nodevice\u0026quot; if there is no corresponding device). (2) The mount point within the filesystem tree. (3) The filesystem type. (4) Optional statistics and configuration information. Currently (as at Linux 2.6.26), only NFS filesystems export information via this field. PID namespace PID namespace는 프로세스 ID 공간을 격리 시킵니다. 이 말인 즉, 다른 PID namespace의 프로세스들은 같은 PID를 가질 수도 있음을 의미합니다. PID namespace들은 프로세스 집합의 종료, 재시작과 같은 기능을 제공하기 위한 컨테이너를 허용합니다. 또한 컨테이너를 새로운 호스트로 마이그레이션하는 등의 기능을 컨테이너가 제공할 수 있도록 해줍니다.\nPID namepsace의 특이한 점은 새로운 PID namespace의 PID는 1 부터 시작한다는 것입니다. standalone 시스템과 동일하게 각 namespace의 시작 프로세스는 pid를 1번을 가지게됩니다.\nPID namespace를 사용하기 위해선 CONFIG_PID_NS 커널 옵션을 설정해야 합니다.\nUser namespace User namespace는 시큐리티와 관련된 식별자 및 속성을 분리하며, 특히 User ID와 Group ID, 루트 디렉토리, Key, Capability를 분리합니다. 프로세스의 User, Group ID는 user namespace 내,외부적으로 다를수 있습니다. 특히 프로세스는 User namespace 외부에 권한이 없는 정상적인 User ID를 가질 수 있으며, 동시에 namepsace 내부에 User ID 0을 가질 수 있습니다. 즉, 프로세스에는 user namespace 내의 작업에 대한 전체 권한이 있지만 namespace 외부 작업에 대한 권한이 없습니다. 자세한 내용은 다른 글로 살펴보겠습니다.\nUTS namespace UTS namespace는 두개의 시스템 식별자를 고립, 격리시킵니다. 두 개의 시스템 식별자는 hostname과 NIS domain name입니다. 이 식별자들은 sethostname(2), **setdomainname(2)**으로 설정가능합니다. UTS namespace의 사용은 CONFIG_UTS_NS 커널 옵션을 설정해야 합니다.\n이상으로 Namespace에 대해 간단히 정리해보았습니다. 다음 글에서 각 namespace의 사용 및 예제에 대해 다뤄보겠습니다.\n감사합니다.\n감사합니다.\n"
},
{
	"uri": "https://linuxias.github.io/container/cgroup/2.cgroup_blkio/",
	"title": "2. blkio",
	"tags": [],
	"description": "",
	"content": "Subsystem - blkio blkio 서브시스템은 특정 block device에 대한 접근을 제한하거나 제어하기 위한 서브시스템 입니다. 자세한 내용은 ** Documentation/cgroup-v1/blkio-controller.txt ** 를 참고해주세요.\n예제 살펴보기 I/O 작업이 많은 몇몇의 어플리케이션이 하나의 서버에서 동작한다고 가정합니다. 각 어플리케이션에 대해 다른 우선순위와 I/O 대역폭을 설정해주는 예제를 살펴보겠습니다.\n cgroup 가상파일시스템을 마운트합니다.  $ sudo mkdir -p /cgroup/blkio $ sudo mount -t cgroup -o blkio blkio /cgroup/blkio 마운트 여부 확인하기. 아래 명령어를 수행해서 결과가 표시된다면 정상적으로 마운트되었습니다.  $ mount | grep cgroup blkio on /cgroup/blkio type cgroup (rw,relatime,blkio) or $ cat /proc/mount | grep cgroup blkio /cgroup/blkio cgroup rw,relatime,blkio 0 0 mount 상태 확인해보기.  linuxias@linuxias-VirtualBox:/cgroup/blkio$ ls -al total 4 dr-xr-xr-x 2 root root 0 8월 11 13:35 . drwxr-xr-x 3 root root 4096 8월 6 17:07 .. -r--r--r-- 1 root root 0 8월 11 13:55 blkio.io_merged -r--r--r-- 1 root root 0 8월 11 13:55 blkio.io_merged_recursive -r--r--r-- 1 root root 0 8월 11 13:55 blkio.io_queued -r--r--r-- 1 root root 0 8월 11 13:55 blkio.io_queued_recursive -r--r--r-- 1 root root 0 8월 11 13:55 blkio.io_service_bytes -r--r--r-- 1 root root 0 8월 11 13:55 blkio.io_service_bytes_recursive -r--r--r-- 1 root root 0 8월 11 13:55 blkio.io_serviced -r--r--r-- 1 root root 0 8월 11 13:55 blkio.io_serviced_recursive -r--r--r-- 1 root root 0 8월 11 13:55 blkio.io_service_time -r--r--r-- 1 root root 0 8월 11 13:55 blkio.io_service_time_recursive -r--r--r-- 1 root root 0 8월 11 13:55 blkio.io_wait_time -r--r--r-- 1 root root 0 8월 11 13:55 blkio.io_wait_time_recursive -rw-r--r-- 1 root root 0 8월 11 13:55 blkio.leaf_weight -rw-r--r-- 1 root root 0 8월 11 13:55 blkio.leaf_weight_device --w------- 1 root root 0 8월 11 13:55 blkio.reset_stats -r--r--r-- 1 root root 0 8월 11 13:55 blkio.sectors -r--r--r-- 1 root root 0 8월 11 13:55 blkio.sectors_recursive -r--r--r-- 1 root root 0 8월 11 13:55 blkio.throttle.io_service_bytes -r--r--r-- 1 root root 0 8월 11 13:55 blkio.throttle.io_serviced -rw-r--r-- 1 root root 0 8월 11 13:55 blkio.throttle.read_bps_device -rw-r--r-- 1 root root 0 8월 11 13:55 blkio.throttle.read_iops_device -rw-r--r-- 1 root root 0 8월 11 13:55 blkio.throttle.write_bps_device -rw-r--r-- 1 root root 0 8월 11 13:55 blkio.throttle.write_iops_device -r--r--r-- 1 root root 0 8월 11 13:55 blkio.time -r--r--r-- 1 root root 0 8월 11 13:55 blkio.time_recursive -rw-r--r-- 1 root root 0 8월 11 13:55 blkio.weight -rw-r--r-- 1 root root 0 8월 11 13:55 blkio.weight_device -rw-r--r-- 1 root root 0 8월 11 13:55 cgroup.clone_children -rw-r--r-- 1 root root 0 8월 11 13:35 cgroup.procs -r--r--r-- 1 root root 0 8월 11 13:55 cgroup.sane_behavior -rw-r--r-- 1 root root 0 8월 11 13:55 notify_on_release -rw-r--r-- 1 root root 0 8월 11 13:55 release_agent -rw-r--r-- 1 root root 0 8월 11 13:55 tasks 마운트한 디렉토리에서 내부 리스트를 확인해보니 위와 같이 많은 파일들이 생성되었습니다. 그 중 우리가 write할 수 있는 파일은 몇 개 되지 않네요. 나머지는 모두 read만 할 수 있습니다. 그 말은 우리가 cgroup blkio 서브시스템을 사용하여 제어할 수 있는 요소들은 write 권한이 있는 파일들을 유심히 보면 될 것 같습니다.\n특정 프로세스들을 high_io와 low_io 그룹에 할당하기. 특정 프로세스의 PID가 각각 10001, 10002 라고 해봅시다.  $ echo 10001 \u0026gt;\u0026gt; /cgroup/blkio/high_io/tasks $ echo 10002 \u0026gt;\u0026gt; /cgroup/blkio/high_io/tasks 위와 같이 설정하거나 프로세스의 이름이 test 라고 할 때\n$pidof test | while read PID; do echo $PID \u0026gt;\u0026gt; /cgroup/blkio/high_io/tasks; done 으로도 설정할 수 있습니다.\nhigh_io 와 low_io에 대해 가중치 비율 설정하기  $ echo 200 \u0026gt; /cgroup/blkio/high_io/blkio.weight $ echo 100 \u0026gt; /cgroup/blkio/low_io/blkio.weight 2:1 비율로 가중치를 설정하였습니다.\nblkio 파일 설명 아래 몇 가지 파일에 대한 내용을 표로 작성해두었습니다. 그 외 다른 파일에 대한 설명은 Documentation을 보시면 좋습니다.\n   파일 설명     blkio.weight cgroup에 제공되는 장치에 대한 접근 가중치를 적용할 수 있습니다. 상대적인 비율로 100에서 1000까지 설정이 가능하며 설정하지 않을 시 기본 가중치입니다.   blkio.weight_device blkio.weight와 동일하지만 가중치를 적용할 블록 장치를 지정합니다.   blkio.time device 당 cgroup에 할당된 disk time으로 msec 단위입니다. 특정 장치로의 I/O access 시간을 설정할 수 있습니다. 설정을 위해선 디바이스의 major, minor 번호와 msec가 필요합니다.   blkio.io_service_bytes cgroup에 의해 지정된 디바이스에서 송수신한 바이트 수 입니다.   blkio.serviced cgroup에 의해 디바이스에 실행된 I/O 작업의 수 입니다.   blkio.service_time cgroup에 의해 수행된 I/O 작업 요청의 시작부터 완료까지의 총 시간으로 nsec 단위입니다.   blkio.io_wait_time I/O 작업이 지정된 장치에 대해 스케줄러 큐에서 대기한 전체 시간입니다.   blkio.io_merged I/O 작업에 대한 요청으로 병합된 읽기, 쓰기, 동기화 또는 비동기의 수 입니다.    이 외에도 매우 많은 파일들이 존재하는데요. 필요한 내용은 Documentation을 꼭 참고해주세요.\n참고자료  Containerization with LXC | Konstantin Ivanov [Linux] cgroup - (task) control group (1) (http://egloos.zum.com/studyfoss/v/5505982) [Linux] cgroup - (task) control group (1)(http://studyfoss.egloos.com/5506102) Docker(container)의 작동 원리: namespaces and cgroups(https://tech.ssut.me/what-even-is-a-container/) Control Groups | 문C 블로그(http://jake.dothome.co.kr/control-groups/) CGROUPS(7) linux manual page /Documentation/cgroup-v1/blkio-controller.txt  "
},
{
	"uri": "https://linuxias.github.io/container/namespace/2_pid_namespace/",
	"title": "2. PID Namespace",
	"tags": [],
	"description": "",
	"content": "PID namespace는 프로세스 ID 공간을 격리 시킵니다. 이 말인 즉, 다른 PID namespace의 프로세스들은 같은 PID를 가질 수도 있음을 의미합니다. PID namespace들은 프로세스 집합의 종료, 재시작과 같은 기능을 제공하기 위한 컨테이너를 허용합니다. 또한 컨테이너를 새로운 호스트로 마이그레이션하는 등의 기능을 컨테이너가 제공할 수 있도록 해줍니다.\nPID namepsace의 특이한 점은 새로운 PID namespace의 PID는 1 부터 시작한다는 것입니다. standalone 시스템과 동일하게 각 namespace의 시작 프로세스는 pid를 1번을 가지게됩니다. PID namespace를 사용하기 위해선 CONFIG_PID_NS 커널 옵션을 설정해야 합니다.\nThe namespace init process CLONE_NEWPID flag를 파라미터로 한 unshare(2) 시스템 콜을 호출한 이후, 또는 clone(2) 시스템 콜의 flag로 CLONE_NEWPID를 전달하여 생성한 프로세스는 새로운 Namespace의 첫 번째 프로세스가 됩니다. 이 말인 즉, 이 프로세스의 PID가 1번이라는 것입니다.\n조금 혼란스러울 수 있습니다. 리눅스에서 PID는 고유하며, 프로세스의 식별자로 사용이 되는데, 새로운 Namespace의 첫 번째 프로세스의 PID가 1번이라면, 중복될테니까요. 그 이후 이 프로세스에 자식 프로세스들도 2,3,4\u0026hellip; 와 같은 PID를 가질 수 있다는 말이됩니다. 식별자로써의 가치가 사라지게 되는 것일까요? 조금씩 정리해보도록 하겠습니다.\n새로운 PID namespace의 첫 번째 프로세스의 PID가 1번이라고 말씀드렸습니다. 그 의미는 해당 namespace를 위한 init process가 된다는 의미입니다. 아래 그림처럼 새로운 namespace는 PID 1번부터 시작하게 됩니다. 뭔가 속임수 같나요?\n그림 출처 : https://www.toptal.com/linux/separation-anxiety-isolating-your-system-with-linux-namespaces\n만약 8,1 두 개의 PID를 가진 프로세스에서 getpid(2) 시스템 콜을 호출하게 되면, 어떤 결과가 리턴 될까요? 결과는 1입니다. PID를 이용해 동작하는 시스템 콜들은 항상 호출자의 PID namespace 내에 표시되는 PID를 사용하게 됩니다. 그렇기 때문에 child PID namespace에서 표시되는 1이 반환됩니다.\nnamespace 동작 중에 init process가 종료되면 어떻게 될까요? 만약 PID namespace 내의 init process가 종료된다면, 커널은 SIGKILL 시그널을 통해 해당 namespace 내에 모든 프로세스를 종료시키게 됩니다. 이 의미는 PID namespace가 정상적으로 동작하기 위해선 PID 1의 init process가 필수적이란 의미입니다.\ninit process에 시그널을 보낼 수 있는 경우는 시그널 핸들러에 등록한 시그널들만 PID namespace의 다른 프로세스들에 의해 전달될 수 있습니다. 이러한 제한은 권한이 있는 프로세스들에게도 해당되며 실수로 init process가 PID namespace 내의 다른 멤버 프로세스에 의해 종료되는 것을 막아주게됩니다. 마찬가지로 상위 PID namespace의 프로세스는 자식 PID namespace의 init process가 등록한 시그널 **kill(2)**을 호출하여 전달할 수 있습니다. 여기서 SIGKILL과 SIGSTOP은 예외적으로 처리되는데요, 상위 PID namespace에서 시그널을 전달하면 init process에서는 처리할 수 없기에, 해당 시그널이 처리되어 프로세스 종료 및 중지가 발생하게 됩니다.\nNesting PID namespace PID Namespace는 중첩해서 사용이 가능합니다. 그 말은, 각 PID namespace는 상위(부모) namespace를 가지고 있습니다.(root PID namespace는 제외입니다 :D) PID namepsace의 부모 namespace는 clone(2) 또는 **unshare(2)**를 사용하여 namespace를 생성한 프로세스의 PID namepsace가 됩니다. 이러한 구조는 PID namespace가 트리 자료구조 형태로 이루어져 있습니다. 모든 namepsace는 자신의 상위 namespace들(root namespace 포함)을 언제든 찾을 수 있습니다.\n특정 Namespace에 속한 프로세스는 해당 namespace에 속한 프로세스들과, 상위 모든(root namespace로 가는 경로의) namespace 프로세스들에게 보여집니다. 보여진다는 의미는 해당 프로세스를 타겟으로 작업을 진행할 수 있다는 의미입니다. 하지만 반대로 자식 PID namespace에서는 부모나 제거된 상위 namespace의 프로세스들을 볼 수 없습니다. 정리하면, 프로세스는 오직 자신의 PID namsepace의 프로세스들이나 자식 namespace들의 프로세스들만 볼 수 있습니다.\n특정 PID namespace내의 프로세스들은 가끔 namespace 외부에 부모 프로세스를 가지는 경우가 있습니다. 첫 번째는 위에서 살펴보았듯이, Namespace가 생성된 후 첫 프로세스는 자신을 생성한 프로세스가 부모프로세스가 됩니다. 이 경우엔 부모와 자식 프로세스가 각각 다른 PID namespace에 존재하게 됩니다. 두 번째로 setns(2) 시스템콜을 이용하여 특정 PID namespace로 조인하게 되는 경우입니다. 조인할 수 있는 PID namespace는 자식 PID namespace으로만 가능합니다. 완전 다른 방향의 namespace로는 불가능합니다. 잘 생각하셔야 할게 지금 설명드리는 부분은 namespace간 부모, 자식 관계가 아닌 프로세스의 부모, 자식 관계입니다.\n/proc 파일시스템과 PID namespace /proc 파일시스템은 /proc 파일시스템이 다른 Namespace에서 보여지더라도 마운트를 수행한 프로세스의 PID namespace에 보이는 프로세스만 보여줍니다. 새 PID namespace를 만든 후에는 ps (1)와 같은 툴이 정상적으로 작동하도록 /proc 파일시스템에 새로운 procfs 인스턴스를 마운트하고 루트 디렉토리를 변경하는 것이 좋습니다. clone (2) 또는 unshare(2)의 flags에 CLONE_NEWNS를 포함하여 새로운 마운트 네임 스페이스를 동시에 생성하면 루트 디렉토리를 변경할 필요가 없습니다. 새로운 procfs 인스턴스를 /proc에 직접 마운트 할 수 있습니다.\nmount -t proc proc /proc PID namespace는 container에서 유용하게 사용되는 기술 중 하나입니다. 추가적인 내용들은 정리되는대로 갱신하겠습니다. 글 읽어주셔서 감사합니다.\n감사합니다.\n참조 : https://www.toptal.com/linux/separation-anxiety-isolating-your-system-with-linux-namespaces\n"
},
{
	"uri": "https://linuxias.github.io/container/cgroup/3.cgroup_memory/",
	"title": "3. memory",
	"tags": [],
	"description": "",
	"content": "Subsystem - memory memory 서브시스템은 cgroup에서 사용하는 메모리 자원에 대해 프로세스가 사용하는 메모리 양과 사용 가능한 메모리 자원을 컨트롤 할 수 있습니다. 또한 사용되는 메모리 자원에 대한 레포트도 자동으로 생성해주는 서브시스템입니다.\nmemory 서브시스템은 시스템으로부터 태스크의 그룹의 메모리 접근등의 동작을 격리화시킵니다. 이 서브시스템이 사용되는 경우는 다음과 같습니다.\n 메모리 소모가 많은 어플리케이션을 격리하고 더 작은 어플리케이션으로 제한할 수 있습니다. mem=XXXX 설정을 통해 부팅하는 경우의 좋은 대안이 될 수 있습니다. 가상화 솔루션에서 원하는 메모리 양을 제어할 수 있습니다. 위 내용 외에도 여러 요소가 있을 수 있습니다.  예제 살펴보기  cgroup 가상파일시스템을 마운트합니다.  $ sudo mkdir -p /cgroup/memory $ sudo mount -t cgroup -o memory memory /cgroup/memory 마운트 여부 확인하기. 아래 명령어를 수행해서 결과가 표시된다면 정상적으로 마운트되었습니다.  $ mount | grep cgroup memory on /cgroup/memory type cgroup (rw,relatime,blkio) or $ cat /proc/mount | grep cgroup memory /cgroup/memory cgroup rw,relatime,blkio 0 0 mount 상태 확인해보기.  linuxias@linuxias-VirtualBox:/cgroup/memory$ ls -al total 4 dr-xr-xr-x 2 root root 0 8월 11 13:35 . drwxr-xr-x 4 root root 4096 8월 11 15:49 .. -rw-r--r-- 1 root root 0 8월 11 15:49 cgroup.clone_children --w--w--w- 1 root root 0 8월 11 15:49 cgroup.event_control -rw-r--r-- 1 root root 0 8월 11 13:35 cgroup.procs -r--r--r-- 1 root root 0 8월 11 15:49 cgroup.sane_behavior -rw-r--r-- 1 root root 0 8월 11 15:49 memory.failcnt --w------- 1 root root 0 8월 11 15:49 memory.force_empty -rw-r--r-- 1 root root 0 8월 11 15:49 memory.kmem.failcnt -rw-r--r-- 1 root root 0 8월 11 15:49 memory.kmem.limit_in_bytes -rw-r--r-- 1 root root 0 8월 11 15:49 memory.kmem.max_usage_in_bytes -r--r--r-- 1 root root 0 8월 11 15:49 memory.kmem.slabinfo -rw-r--r-- 1 root root 0 8월 11 15:49 memory.kmem.tcp.failcnt -rw-r--r-- 1 root root 0 8월 11 15:49 memory.kmem.tcp.limit_in_bytes -rw-r--r-- 1 root root 0 8월 11 15:49 memory.kmem.tcp.max_usage_in_bytes -r--r--r-- 1 root root 0 8월 11 15:49 memory.kmem.tcp.usage_in_bytes -r--r--r-- 1 root root 0 8월 11 15:49 memory.kmem.usage_in_bytes -rw-r--r-- 1 root root 0 8월 11 13:35 memory.limit_in_bytes -rw-r--r-- 1 root root 0 8월 11 15:49 memory.max_usage_in_bytes -rw-r--r-- 1 root root 0 8월 11 15:49 memory.move_charge_at_immigrate -r--r--r-- 1 root root 0 8월 11 15:49 memory.numa_stat -rw-r--r-- 1 root root 0 8월 11 15:49 memory.oom_control ---------- 1 root root 0 8월 11 15:49 memory.pressure_level -rw-r--r-- 1 root root 0 8월 11 15:49 memory.soft_limit_in_bytes -r--r--r-- 1 root root 0 8월 11 15:49 memory.stat -rw-r--r-- 1 root root 0 8월 11 15:49 memory.swappiness -r--r--r-- 1 root root 0 8월 11 15:49 memory.usage_in_bytes -rw-r--r-- 1 root root 0 8월 11 13:35 memory.use_hierarchy -rw-r--r-- 1 root root 0 8월 11 15:49 notify_on_release -rw-r--r-- 1 root root 0 8월 11 15:49 release_agent -rw-r--r-- 1 root root 0 8월 11 15:49 tasks 마운트한 디렉토리에서 내부 리스트를 확인해보니 위와 같이 많은 파일들이 생성되었습니다. 그 중 우리가 write할 수 있는 파일은 몇 개 되지 않네요. 나머지는 모두 read만 할 수 있습니다. 그 말은 우리가 cgroup blkio 서브시스템을 사용하여 제어할 수 있는 요소들은 write 권한이 있는 파일들을 유심히 보면 될 것 같습니다.\n특정 프로세스의 메모리 설정하기.  $ sudo mkdir /cgroup/memory/test_process $ sudo echo 1G \u0026gt; /cgroup/memory/test_process/memory.limit_in_bytes $ cat /cgroup/memory/test_process/memory.limit_in_bytes 1073741824 cgroup에 적용하기. test process의 pid가 10001 이라고 할 때 아래와 같이 설정해 줍니다.  $ echo 10001 \u0026gt;\u0026gt; /cgroup/memory/test_process/tasks 위와 같이 설정하거나 프로세스의 이름이 test 라고 할 때\n$pidof test | while read PID; do echo $PID \u0026gt;\u0026gt; /cgroup/memory/test_process/tasks; done memory 서브시스템 statistics 확인해보기. memory.stat 파일에는 다양한 통계 정보가 존재합니다. 아래와 같이 확인 하실 수 있습니다.\n$ cat memory.stat cache 912625664 rss 281018368 rss_huge 0 shmem 1433600 mapped_file 178327552 dirty 0 writeback 0 pgpgin 915786 pgpgout 624369 pgfault 1014204 pgmajfault 2469 inactive_anon 536576 active_anon 280662016 inactive_file 379850752 active_file 521773056 unevictable 10792960 hierarchical_memory_limit 9223372036854771712 total_cache 912625664 total_rss 281018368 total_rss_huge 0 total_shmem 1433600 total_mapped_file 178327552 total_dirty 0 total_writeback 0 total_pgpgin 915786 total_pgpgout 624369 total_pgfault 1014204 total_pgmajfault 2469 total_inactive_anon 536576 total_active_anon 280662016 total_inactive_file 379850752 total_active_file 521773056 total_unevictable 10792960 각 정보에 대한 설명은 Documentation file 5.2 stat file 를 참고해주세요.\nmemory 파일 설명 아래 몇 가지 파일에 대한 내용을 표로 작성해두었습니다. 그 외 다른 파일에 대한 설명은 Documentation을 보시면 좋습니다.\n   파일 설명     tasks 태스크를 추가하고, 스레드의 리스트를 볼 수 있습니다.   cgroup.procs 프로세스들의 리스트를 볼 수 있습니다.   cgroup.event_control event_fd() 를 위한 인터페이스 입니다.   memory.usage_in_bytes 현재 메모리 사용량을 표시합니다.   memory.memsw.usage_in_bytes 현재 memory+swap 사용량을 보여줍니다.   memory.limit_in_bytes 메모리 사용량의 제한을 설정 또는 보여줍니다.   memory.memsw.limit_in_bytes memory + swap 메모리 사용량의 제한을 설정 또는 보여줍니다.   memory.failcnt 메모리 사용량 hits 제한을 보여줍니다.   memory.memsw.failcnt memory + swap 메모리 사용량 hits 제한을 보여줍니다.   memory.max_usage_in_bytes 최대 메모리 사용량을 보여줍니다.   memory.memsw.max_usage_in_bytes memory + swap 메모리의 최대 사용량을 보여줍니다.   memory.soft_limit_in_bytes 메모리 사용의 소프트 제한을 설정 또는 보여줍니다.   memory.stat 다양한 statistics를 보여줍니다.   memory.use_hierarchy 자식 프로세스의 메모리 여부를 설정 또는 보여줍니다.   memory.force_empty 0으로 설정하면 작업에서 사용하는 메모리를 해제합니다.   memory.pressure_level 메모리 입력 알람을 설정합니다.   memory.oom_control oom 제어를 설정또는 보여줍니다.   memory.numa_stat Numa 노드 당 메모리 사용의 수를 보여줍니다   memory.kmem.limit_in_bytes 커널 메모리에 대한 hard limit을 설정 또는 보여줍니다.   memory.kmem.usage_in_bytes 현재 커널 메모리 할당을 보여줍니다.   memory.kmem.failcnt 커널 메모리 사용 hits 제한의 수를 보여줍니다.   memory.kmem.max_usage_in_bytes 커널 메모리 사용의 max 값을 보여줍니다.    이 외에도 매우 많은 파일들이 존재하는데요. 필요한 내용은 Documentation을 꼭 참고해주세요.\n참고자료  Containerization with LXC | Konstantin Ivanov [Linux] cgroup - (task) control group (1) (http://egloos.zum.com/studyfoss/v/5505982) [Linux] cgroup - (task) control group (1)(http://studyfoss.egloos.com/5506102) Docker(container)의 작동 원리: namespaces and cgroups(https://tech.ssut.me/what-even-is-a-container/) Control Groups | 문C 블로그(http://jake.dothome.co.kr/control-groups/) CGROUPS(7) linux manual page https://www.kernel.org/doc/Documentation/cgroup-v1/memory.txt  "
},
{
	"uri": "https://linuxias.github.io/container/namespace/3.user_namespace/",
	"title": "3. User Namespace",
	"tags": [],
	"description": "",
	"content": " 먼저 이 글에서 사용한 코드는 linux kernel 4.16 임을 알려드립니다.\n User namespace는 시큐리티와 관련된 식별자 및 속성을 분리하며, 특히 User ID와 Group ID, 루트 디렉토리, Key, Capability를 분리합니다. 프로세스의 User, Group ID는 user namespace 내,외부적으로 다를수 있습니다. 특히 프로세스는 User namespace 외부에 권한이 없는 정상적인 User ID를 가질 수 있으며, 동시에 namepsace 내부에 User ID 0을 가질 수 있습니다. 즉, 프로세스에는 user namespace 내의 작업에 대한 전체 권한이 있지만 namespace 외부 작업에 대한 권한이 없습니다.\nNested namespaces, Namespace membership User namespace는 PID namespace 처럼 중첩되어 질 수 있습니다. 이 말은 root namespace를 제외하고 각 User namespace는 부모 user namespace를 가질 수 있다는 것입니다. 다른 관점에서 본다면 User namespace는 0개 또는 그 이상의 자식 User namespace를 가질 수 있습니다. 부모 User namespace는 CLONE_NEWUSER flag를 사용한 unshare(2) 또는 clone(2) 시스템콜을 통해 user namespace를 생성하는 프로세스의 namespace입니다. 음, 새로 생성된 namespace는 그 namespace를 생성하는 프로세스의 namespace를 부모 namespace로 가진다는 의미입니다.\n커널은 이렇게 중첩할 수 있는 user namespace의 레벨을 32개로 제한하고 있습니다.\n아래 struct user_namespace를 살펴보시죠. 아래 line.61에 int level; 구조체 멤버변수가 보이시나요? user namespace 는 이처럼 레벨을 관리하고 있습니다.\nFile path : include/linux/user_namespace.h 55 struct user_namespace { 56 struct uid_gid_map uid_map; 57 struct uid_gid_map gid_map; 58 struct uid_gid_map projid_map; 59 atomic_t count; 60 struct user_namespace *parent; 61 int level; 62 kuid_t owner; 63 kgid_t group; 64 struct ns_common ns; 65 unsigned long flags; 66 67 /* Register of per-UID persistent keyrings for this namespace */ 68 #ifdef CONFIG_PERSISTENT_KEYRINGS 69 struct key *persistent_keyring_register; 70 struct rw_semaphore persistent_keyring_register_sem; 71 #endif 72 struct work_struct work; 73 #ifdef CONFIG_SYSCTL 74 struct ctl_table_set set; 75 struct ctl_table_header *sysctls; 76 #endif 77 struct ucounts *ucounts; 78 int ucount_max[UCOUNT_COUNTS]; 79 } __randomize_layout; 만약 limit을 초과하게 되면 EUSERS 에러가 발생하게 됩니다.\n모든 프로세스들은 User namespace 중 하나에 속합니다. 여러분들이 프로세스 생성에 많이 사용하는 fork(2), **clone(2)**을 사용할 때 flag로 CLONE_NEWUSER를 전달하지 않는다면 해당 시스템 콜을 호출한 프로세스의 User namespace에 속하게 됩니다. 싱글스레드 프로세스는 setns(2) 시스템 콜을 사용하여 다른 user namespace로 포함될 수 있습니다. 조건은 setns(2) 시스템 콜을 호출하는 프로세스가 CAP_SYS_ADMIN Capability를 가지고 있어야 합니다.\n여기서 주의할 점은 멀티스레드 프로세스에서는 setns(2) 시스템 콜을 호출한 스레드만 namespace가 변경되어 버립니다. 그럼, 이상한 문제점들이 발생하게 될겁니다.\n하나의 스레드만 적용되는 이유는 아래 코드에서 확인할 수 있습니다. setns(2) 시스템 콜을 호출하게 되면 아래 함수가 수행됩니다. 여기서 line.268을 확인해보시면 현재 task_struct를 가져오게되고, line.283에서 task_struct를 가져와 namespace를 생성하게 되는데, 스레드는 각각의 task_struct를 가지고 있기에, 해당 thread에 대해서만 변경이 됩니다.\nFile path : kernel/nsproxy.c 266 SYSCALL_DEFINE2(setns, int, fd, int, nstype) 267 { 268 struct task_struct *tsk = current; 269 struct nsproxy *new_nsproxy; 270 struct file *file; 271 struct ns_common *ns; 272 int err; 273 274 file = proc_ns_fget(fd); 275 if (IS_ERR(file)) 276 return PTR_ERR(file); 277 278 err = -EINVAL; 279 ns = get_proc_ns(file_inode(file)); 280 if (nstype \u0026amp;\u0026amp; (ns-\u0026gt;ops-\u0026gt;type != nstype)) 281 goto out; 282 283 new_nsproxy = create_new_namespaces(0, tsk, current_user_ns(), tsk-\u0026gt;fs); 284 if (IS_ERR(new_nsproxy)) { 285 err = PTR_ERR(new_nsproxy); 286 goto out; 287 } 288 289 err = ns-\u0026gt;ops-\u0026gt;install(new_nsproxy, ns); 290 if (err) { 291 free_nsproxy(new_nsproxy); 292 goto out; 293 } 294 switch_task_namespaces(tsk, new_nsproxy); 295 296 perf_event_namespaces(tsk); 297 out: 298 fput(file); 299 return err; 300 } Capability CLONE_NEWUSER flag를 이용하여 clone(2) 시스템 콜로 생성된 자식 프로세스는 새로운 User namespace에서 완전한 Capability 집합을 가지고 실행됩니다. 마찬가지로 unshare(2), setns(2) 시스템 콜도 마찬가지로 Namepsace 내부에서 Capability의 전체 집합을 가지게 됩니다.\n반면에, 새로운 네임 스페이스가 생성 되더라도 그 프로세스는 부모 네임 스페이스 (클론 (2)의 경우) 또는 이전 (unshare(2) 및 **setns(2)**의 경우) User namepsace의 CCapability를 갖지 않습니다 또는 루트 사용자 (즉, Root User namepsace에서 사용자 ID가 0 인 프로세스)에 의해 조인됩니다.\n다른 경우로서, **execve(2)**를 호출하면 프로세스의 기능이 일반적인 방법으로 재계산됩니다 이 방식은 이 글의 범위를 벗어나기 때문에 다루지 않겠습니다. 관심있으신 분은 capabilites(7) 을 참조해주세요결과적으로 Namespace 내에 프로세스의 사용자 ID가 0이 아니거나 실행 가능 파일에 비어 있지 않은 상속 기능 마스크가 있으면 프로세스가 모든 기능을 잃게됩니다. 음, 자세한 내용은 아래에서 다시 다루겠습니다.\nclone(2) 또는 unshared(2) 를 이용해 새로운 IPC, mount, network, PID, UTS namespace를 생성할 때 커널은 새로운 Namespace에 대해 생성한 프로세스의 User namespace를 기록합니다. 새로운 Namespace의 프로세스가 나중에 Namespace 내에 격리된 전역 리소스에서 작동하는 권한 작업을 수행하면 커널이 새 Namespace와 연결된 User namespace의 프로세스 Capability에 따라 검사가 수행됩니다. 즉 Namepsace의 Capability는 User namespace와 상호작용하며 체크하게 된다는 것입니다.\nRestrictions on mount namespaces mount namespace 관련하여 정리한 내용입니다.\nmount namespace는 owner user namespace를 가지고 있습니다. owner user namespace가 상위 mount namespace의 owner user namespace와 다른 mount namespace는 권한이 낮은 mount namespace로 간주됩니다. 낮은 권한의 mount namespace가 생성될 때 공유 마운트는 슬레이브 마운트로 축소됩니다. 이렇게하면 권한이 낮은 mount namespace에서 수행 된 매핑이보다 많은 권한을 가진 mount namespace로 전파되지 않습니다.\n더 많은 권한을 가진 마운트에서 하나의 단위로 나오는 마운트는 함께 잠기고 특권이 적은 mount namespace에서 분리되지 않을 수 있습니다.\n파일 및 디렉토리에 대해서는 다른 namespace 마운트 지점이 아닌 하나의 namespace의 마운트 지점인 파일 또는 디렉터리는 마운트 지점이 아닌 mount namespace에서 이름을 변경하거나 연결 해제하거나 제거(rmdir(2))할 수 있다. 다른 mount namespace에서 마운트 포인트의 파일, 디렉토리를 삭제, rename, unlink를 시도하게 되면 EBUSY 에러가 나타납니다. 이런 결과는 특권이 많은 사용자로부터 DoS 공격을 막기 위한 방안입니다.\nInteraction of user namespaces and other types of namespaces User 네임스페이스는 다른 네임스페이스들과 연관관계를 맺고있습니다.\n리눅스 커널 3.8부터 권한이 없는(unprivileged) 프로세스들도 User 네임스페이스를 생성할 수 있습니다. 프로세스가 CAP_SYS_ADMIN Capability 를 가지고 있다면 Mount, PID, IPC, Network, UTS 네임스페이스도 생성할 수 있습니다.\nNon-user 네임스페이스(User 네임스페이스를 제외한 다른 네임스페이스)가 생성될 때 새로운 프로세스는 자신을 생성한 프로세스가 속한 User 네임스페이스에 속하게 됩니다. Non-user 네임스페이스은 User 네임스페이스의 기능이 필요합니다. 만약 ** clone(2) ** 또는 ** unshare(2) ** 호출 시 ** CLONE_NEWUSER ** 가 다른 ** CLONE_NEW* ** 플래그와 함께 명시된다면 User 네임페이스를 먼저 생성하게 됩니다. 그 이후 권한을 확인하여 나머지 네임스페이스의 생성을 하게 됩니다. 따라서 권한이 없는 호출 프로세스는 이와 같은 플래그의 조합으로 시스템 콜을 호출할 수 있습니다.\n새로운 IPC, mount, network, PID, UTS 네임스페이스가 ** clone(2) ** 또는 **unshare(2) ** 시스템 콜을 통해 생성되면 커널은 새로운 네임스페이스에 대해 생성되는 프로세스의 사용자 네임스페이스를 기록합니다. 새로운 네임스페이스의 프로세스가 네임스페이스 격리된 전역 리소스에서 동작하는 권한이 필요한 작업을 연속적으로 수행하면 커널이 새로운 네임스페이스와 연결된 User 네임스페이스의 새로운 프로세스 기능에 따라 권한을 검사하게 됩니다.\nUser 네임스페이스는 다른 네임스페이스들과 연관관계를 맺고 있는 부분을 확인 할 수 있으며, 특권(Capability)와 권한(Privilege)에 대한 관계도 관련이 있음을 알 수 있습니다.\nUser and Group ID mapplings : uid_map and gid_map User 네임스페이스가 생성되면 상위 User 네임스페이스에 User, Group ID가 매핑되지 않고 시작합니다. ** /proc/[pid]/uid_map ** 과 ** /proc/[pid]/gid_map ** 파일은 해당 프로세스의 User 네임스페이스 내부의 사용자와 그룹 ID 매핑 정보를 보여줍니다. 이 정보는 Namespace(1) 글에서 자료구조 내부적으로 어떻게 관리하는지 본 적이 있습니다.\n55 struct user_namespace { 56 struct uid_gid_map uid_map; 57 struct uid_gid_map gid_map; 58 struct uid_gid_map projid_map; 59 atomic_t count; 60 struct user_namespace *parent; 61 int level; 62 kuid_t owner; 63 kgid_t group; 64 struct ns_common ns; 65 unsigned long flags; 66 67 /* Register of per-UID persistent keyrings for this namespace */ 68 #ifdef CONFIG_PERSISTENT_KEYRINGS 69 struct key *persistent_keyring_register; 70 struct rw_semaphore persistent_keyring_register_sem; 71 #endif 72 struct work_struct work; 73 #ifdef CONFIG_SYSCTL 74 struct ctl_table_set set; 75 struct ctl_table_header *sysctls; 76 #endif 77 struct ucounts *ucounts; 78 int ucount_max[UCOUNT_COUNTS]; 79 } __randomize_layout; 위 구조체에서 uid_map, gid_map이 구조체의 멤버로 존재하며, user_namespace 구조체 내부에서 관리하고 있음을 알 수 있습니다.\n"
},
{
	"uri": "https://linuxias.github.io/container/cgroup/4.cpu.cpuset.cpuacct/",
	"title": "4. cpu, cpuset, cpuaccet",
	"tags": [],
	"description": "",
	"content": "Subsystem - cpu, cpuset 이번 글에서는 Cgroup의 서브시스템 중 cpu와 cpuset 에 대해 정리해보겠습니다.\ncpu subsystem cpu 서브시스템은 cgroup 계층 및 해당 작업에 대한 CPU 시간을 스케쥴링 할 수 있습니다. 시스템이 busy 상태일 때 CPU 공유를 최소화 즉 사용량을 제한 할 수 있습니다. 이 서브시스템은 CPU에 cgroup 작업 액세스를 제공하기 위한 스케줄러(Documentation/scheduler/sched-design-CFS.txt)를 제공합니다.\ncpuset subsystem cpuset 서브시스템은 개별 CPU 및 메모리 노드를 cgroup에 바인딩 하기 위한 서브시스템입니다. 리눅스의 testset 명령과 유사하게 CPU 코어를 할당 할 수 있는 서브시스템 입니다.\ncpu, cpuset 이 두 서브시스템을 이용하면 CPU 사용량이 많은 어플리케이션에 대해 프로세서 코어들을 할당 및 제어할 수 있으므로 더욱 좋은 활용성을 가질 수 있습니다.\nimage 참고 : 문C블로그 (http://jake.dothome.co.kr/control-groups/)\nCPU 코어 별로 원하는 Task 들을 할당할 수 있어 코어 간 스위칭 되는 로드를 감소할 수 있으며 입맛에 맞게 그룹을 조정할 수 있습니다. 즉 컨테이너 환경에서도 각 컨테이너 별로 다양한 인스터스를 생성할 수 있습니다.\nCPU 예제 살펴보기 몇몇의 프로세스에 대해 설정하는 방법에 대해 알아보겠습니다. 여기서는 cpu와 cpuacct 함께 설정합니다.\n cgroup 가상파일시스템을 마운트합니다.  $ sudo mkdir -p /cgroup/cpu $ sudo mount -t cgroup -o cpu,cpuacct cpu,cpuacct /cgroup/cpu 마운트 여부 확인하기. 아래 명령어를 수행해서 결과가 표시된다면 정상적으로 마운트되었습니다.  $ mount | grep cgroup cpu,cpuacct on /cgroup/cpu type cgroup (rw,relatime,cpu,cpuacct) or $ cat /proc/mount | grep cgroup cpu,cpuacct /cgroup/cpu cgroup rw,relatime,cpu,cpuacct 0 0 mount 상태 확인해보기.  $ ls -al total 4 dr-xr-xr-x 2 root root 0 8월 11 20:22 . drwxr-xr-x 6 root root 4096 8월 11 20:21 .. -rw-r--r-- 1 root root 0 8월 11 20:22 cgroup.clone_children -rw-r--r-- 1 root root 0 8월 11 20:22 cgroup.procs -r--r--r-- 1 root root 0 8월 11 20:22 cgroup.sane_behavior -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.cpu_exclusive -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.cpus -r--r--r-- 1 root root 0 8월 11 20:22 cpuset.effective_cpus -r--r--r-- 1 root root 0 8월 11 20:22 cpuset.effective_mems -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.mem_exclusive -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.mem_hardwall -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.memory_migrate -r--r--r-- 1 root root 0 8월 11 20:22 cpuset.memory_pressure -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.memory_pressure_enabled -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.memory_spread_page -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.memory_spread_slab -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.mems -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.sched_load_balance -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.sched_relax_domain_level -rw-r--r-- 1 root root 0 8월 11 20:22 notify_on_release -rw-r--r-- 1 root root 0 8월 11 20:22 release_agent -rw-r--r-- 1 root root 0 8월 11 20:22 tasks 마운트한 디렉토리에서 내부 리스트를 확인해보니 위와 같이 많은 파일들이 생성되었습니다. 그 중 우리가 write할 수 있는 파일은 몇 개 되지 않네요. 나머지는 모두 read만 할 수 있습니다. 그 말은 우리가 cgroup blkio 서브시스템을 사용하여 제어할 수 있는 요소들은 write 권한이 있는 파일들을 유심히 보면 될 것 같습니다.\n특정 프로세스의 CPU 제한 설정하기. 새로운 계층구조를 생성하고 60%를 할당합니다.  $ sudo mkdir /cgroup/cpu/limit_60_percent $ sudo echo 600 \u0026gt; /cgroup/cpu/limit_60_percent/cpu.shares cgroup에 적용하기. test process의 pid가 10001 이라고 할 때 아래와 같이 설정해 줍니다.  $ echo 10001 \u0026gt;\u0026gt; /cgroup/cpu/limit_60_percent/tasks 위와 같이 설정하거나 프로세스의 이름이 test 라고 할 때\n$pidof test | while read PID; do echo $PID \u0026gt;\u0026gt; /cgroup/cpu/limit_60_percent/tasks; done CPUSET 예제 살펴보기 몇몇의 프로세스에 대해 설정하는 방법에 대해 알아보겠습니다.\n cgroup 가상파일시스템을 마운트합니다.  $ sudo mkdir -p /cgroup/cpuset $ sudo mount -t cgroup -o cpuset cpuset /cgroup/cpuset 마운트 여부 확인하기. 아래 명령어를 수행해서 결과가 표시된다면 정상적으로 마운트되었습니다.  $ mount | grep cgroup cpuset on /cgroup/cpuset type cgroup (rw,relatime,cpuset) or $ cat /proc/mount | grep cgroup cpuset /cgroup/cpuset cgroup rw,relatime,cpuset 0 0 mount 상태 확인해보기.  $ ls -al total 4 dr-xr-xr-x 2 root root 0 8월 11 20:22 . drwxr-xr-x 6 root root 4096 8월 11 20:21 .. -rw-r--r-- 1 root root 0 8월 11 20:22 cgroup.clone_children -rw-r--r-- 1 root root 0 8월 11 20:22 cgroup.procs -r--r--r-- 1 root root 0 8월 11 20:22 cgroup.sane_behavior -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.cpu_exclusive -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.cpus -r--r--r-- 1 root root 0 8월 11 20:22 cpuset.effective_cpus -r--r--r-- 1 root root 0 8월 11 20:22 cpuset.effective_mems -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.mem_exclusive -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.mem_hardwall -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.memory_migrate -r--r--r-- 1 root root 0 8월 11 20:22 cpuset.memory_pressure -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.memory_pressure_enabled -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.memory_spread_page -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.memory_spread_slab -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.mems -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.sched_load_balance -rw-r--r-- 1 root root 0 8월 11 20:22 cpuset.sched_relax_domain_level -rw-r--r-- 1 root root 0 8월 11 20:22 notify_on_release -rw-r--r-- 1 root root 0 8월 11 20:22 release_agent -rw-r--r-- 1 root root 0 8월 11 20:22 tasks 마운트한 디렉토리에서 내부 리스트를 확인해보니 위와 같이 많은 파일들이 생성되었습니다. 그 중 우리가 write할 수 있는 파일은 몇 개 되지 않네요. 나머지는 모두 read만 할 수 있습니다. 그 말은 우리가 cgroup blkio 서브시스템을 사용하여 제어할 수 있는 요소들은 write 권한이 있는 파일들을 유심히 보면 될 것 같습니다.\n특정 프로세스의 cpucore 할당 설정하기.  $ sudo mkdir /cgroup/cpuset/test $ sudo echo 0-1 \u0026gt; /cgroup/cpuset/test/cpuset/cpus cgroup에 적용하기. test process의 pid가 10001 이라고 할 때 아래와 같이 설정해 줍니다.  $ echo 10001 \u0026gt;\u0026gt; /cgroup/cpuset/test/cpuset.cpus 위와 같이 설정하거나 프로세스의 이름이 test 라고 할 때\n$pidof test | while read PID; do echo $PID \u0026gt;\u0026gt; /cgroup/cpuset/test/cpuset.cpus; done 참고자료  Containerization with LXC | Konstantin Ivanov [Linux] cgroup - (task) control group (1) (http://egloos.zum.com/studyfoss/v/5505982) [Linux] cgroup - (task) control group (1)(http://studyfoss.egloos.com/5506102) Docker(container)의 작동 원리: namespaces and cgroups(https://tech.ssut.me/what-even-is-a-container/) Control Groups | 문C 블로그(http://jake.dothome.co.kr/control-groups/) CGROUPS(7) linux manual page https://www.kernel.org/doc/Documentation/cgroup-v1/cpusets.txt https://www.kernel.org/doc/Documentation/cgroup-v1/cpuacct.txt  "
},
{
	"uri": "https://linuxias.github.io/container/namespace/4.qemu/",
	"title": "4. QEMU",
	"tags": [],
	"description": "",
	"content": "Introduction QEMU는 고속의 동적 바이너리 변환 기법을 사용하는 프로세서 에뮬레이터이자 가상화 하이퍼바이저 입니다. 여기서 바이너리 변환이란 하나의 Instruction Set을 다른 Instruction Set으로 번환해주는 처리과정을 말하며, 정적 또는 동적인 방법이 존재합니다.\nQEMU에 대해 정리하기 앞서 QEMU와 KVM을 굉장히 많은 분들이 헷갈려 하시는데, 아래 블로그에 매우 자세하게 정리가 되어 있으니 참고하시면 좋을 것 같습니다.\n[Qemu와 KVM의 개념 - 에뮬레이션과 가상화][http://blog.naver.com/PostView.nhn?blogId=alice_k106\u0026amp;logNo=221179347223\u0026amp;parentCategoryNo=7\u0026amp;categoryNo=\u0026amp;viewDate=\u0026amp;isShowPopularPosts=true\u0026amp;from=search]\n이 글에서는 KVM이 아닌 QEMU에 관한 내용만 정리하려 합니다.\n처음 QEMU 개발 시에는 x86 기반이 아닌 아키텍처에서 x86 기반의 리눅스 응용 프로그램을 실행하는 목적으로 개발되었다고 합니다. 하지만 지금은 x86, ARM 등 다양한 아키텍처를 지원하고 있습니다.\nQEMU가 에뮬레이터로 사용될 때에는 특정 하드웨어 기반에서 실행 가능하도록 작성된 OS나 프로그램을 아키텍처의 변경없이 다른 하드웨어에서 실행되도록 하는 역할을 합니다. 하이퍼바이저로 사용될 때에는 KQEMU를 통해 게스트 OS의 코드를 호스트 시스템의 CPU에서 직접 실행하기 때문에 높은 성능이 발휘됩니다.\n또한 QEMU는 Xen 또는 KVM 하이퍼바이너의 가상화 기능을 도와주는 역할을 수행하기도 하는데, 이 경우 하드웨어 디바이스들의 에뮬레이터 기능을 수행하기 위해 변형된 형태의 QEMU 버전이 사용됩니다.\nArchitecture 하이퍼바이저에는 두 가지 타입이 있습니다. 베어메탈 (TYPE1)과 호스티드 (TYPE2) 방식입니다. 베어메탈 방식은 하드웨어 위에서 HOST OS없이 바로 실행되는 하이퍼바이저를 말하며, 호스티드 방식은 HOST OS 위에서 하이퍼바이저를 실행하여 GUEST OS를 실행하는 방식입니다. QEMU는 TYPE2 방식에 속합니다. QEMU는 두 가지 모드를 제공하고 있는데요, 전체 시스템 모드와 사용자 모드 에뮬레이션을 제공하고 있습니다. 전체 시스템 모드는 CPU 및 주변 장치들을 포함하는 전체 시스템을 에뮬레이션 합니다. 사용자 모드 에뮬레이션은 사용자가 특정 아키텍처에서 동작시키기 위해 크로스 컴파일 한 프로세스를 다른 아키텍처에서 실행할 수 있도록 해줍니다. 특정 프로그램만 빠르게 동작시켜보기 위해서는 사용자 모드를 사용하는게 편합니다.\nHypervisor QEMU는 KVM과 밀접한 관계가 있습니다. KVM은 리눅스 커널에 포함된 모듈로서 하이퍼바이저입니다. kVM 하이퍼바이저에서의 QEMU는 KVM에 최적화되어 변형된 버전인 ** qemu-kvm ** 이 실행되어서 x86 아키텍처에 대한 에뮬레이션을 제공합니다. QEMU는 호스트와 동일한 아키텍처의 OS를 실행하고자 할 떄만 KVM 가속화 기능을 사용합니다.\n"
},
{
	"uri": "https://linuxias.github.io/container/namespace/5_mount_namespace/",
	"title": "5. Mount namespace",
	"tags": [],
	"description": "",
	"content": "mount namespace는 프로세스와 그 자식 프로세스에게 다른 파일시스템 마운트 포인트를 제공합니다. 각 namespace instance의 프로세스들에게 보여지는 마운트 포인트를 격리시키는 기능을 제공합니다. 이렇게 격리된 마운트 포인트는 각 프로세스에게 단일 디렉토리 구조로 보여지게됩니다.\n처음 설치된 시스템에서는 기본적으로 모든 프로세스가 하나의 mount namespaece(기본 namespace)에 속하기 때문에 파일시스템를 마운트하거나 해제하는 등의 모든 사항을 확인 및 인지할 수 있습니다.\nclone(2) 또는 unshare() 시스템 콜과 CLONE_NEWNS 플래그를 사용하여 새로운 프로세스를 생성하면 생성하는 프로세스의 mount namespace를 그대로 복사하여 생성하게 됩니다.\nmount의 종류 mount 할 때 private, shared, slave 옵션을 이용하여 mount를 할 수 있습니다. 각 방식의 차이는 아래와 같습니다.\n   mount 설명     private mount 각 마운트 포인트가 다른 마운트 포인트에 반영되지 않는 방법   shared mount 각 마운트 포인트가 다른 마운트 포인트에 반영되어 보여지는 방법(양방향)   slave mount A 파일시스템 하위에서 새로운 마운트는 B 파일시스템에 반영되나, 반대는 반영되지 않는 방법(단방향)    manual page를 검색하면 아래와 같이 나뉘어져 있습니다.\n source(A) shared private slave unbind ────────────────────────────────────────────────────────────────── dest(B) shared | shared shared slave+shared invalid nonshared | shared private slave unbindable  Restriction on mount namespace   mount namespace는 owner user namespace를 가지고 있습니다. 부모 mount namespace의 owner user namespace와 다른 mount namespace는 그 권한이 낮다고 판단할 수 있습니다.\n  권한이 낮은 mount namespace를 생성할 때, shared mount namespace는 slave mounts로 권한이 낮아집니다.\n  실습  임시 디렉토리를 생성한다.  linuxias$ mkdir /tmp/mount_ns unshare(1) 를 이용하여 새로운 bash 프로세스를 생성할 때 새로운 마운트 네임스페이스를 생성한다.  linuxias$ sudo unshare -m /bin/bash bash 프로세스가 별도의 네임스페이스에 속함을 확인한다. readlink 명령어를 이용해 네임스페이스의 inode 번호를 확인한다.  root# readlink /proc/$$/ns/mount mnt:[4026532199] 임시 마운트 지점을 생성하여 1번에서 생성한 디렉토리에 마운트 시킨다.  root# mount -n -t tmpfs tmpfs /tmp/mount_ns 새로 생성한 마운트 지점을 확인한다.  root# mount | grep mount_ns or root# cat /proc/mounts | grep mount_ns 새로운 터미널을 열고, 네임스페이스 inode를 확인한다.  linuxias$ readlink /proc/$$/ns/mount mnt:[4026531840] 새로운 터미널에서 마운트 지점을 확인한다.  linuxias$ mount | grep mount_ns or linuxias$ cat /proc/mounts | grep mount_ns 위 실습을 통해 알 수 있는 것은 새로 생성한 mount namespace 내에서 새로운 마운트 지점을 생성해도 기본 namespace에서는 알 수 없다는 것이다. 즉 독립화 되어 동작하게 됩니다.\n참고자료 및 문헌  Konstantin Ivanov | Containerization with LXC linux manual page - mount_namespace  "
},
{
	"uri": "https://linuxias.github.io/container/namespace/6.uts_namespace/",
	"title": "6. UTS namespace",
	"tags": [],
	"description": "",
	"content": "UTS(Unix TimeSharing) namespace는 리눅스 컨테이너가 ** hostname -f ** 명령어에 의해 반환된 결과 값인 자신의 식별자를 유지관리하기 위해 hostname과 domainname을 namespace 별로 격리해줍니다. 격리하는 대상은 구별을 위한 식별자가 됩니다. 단순하게 생각하면 hostname은 호스트 각각의 이름이고 domainname은 그룹의 이름입니다. 기본적으로 domainname을 설정하지 않았다면 none으로 표시됩니다.\nUTS namespace로 분리할 수 있는 식별자는 sethostname(2)과 setdomainname(2)을 사용하여 설정되며 unname(2), gethostname(2) 및 getdomainname(2)을 사용하여 검색할 수 있습니다.\nunshare 또는 clone 시스템 콜 호출 시에 CLONE_NEWUTS 플래그를 사용하면 새로운 UTS namespace를 생성하고 해당 namespace를 가진 프로세스를 생성할 수 있습니다.\n실습  ** unshare ** 를 이용하여 새로운 UTS namespace를 만들어서 bash 프로세스를 실행합니다. 그 후 namespace를 변경합니다.   linuxias@linuxias-VirtualBox:~$ hostname linuxias-VirtualBox linuxias@linuxias-VirtualBox:~$ sudo unshare -u /bin/bash [sudo] password for linuxias: root@linuxias-VirtualBox:~# hostname linuxias-VirtualBox root@linuxias-VirtualBox:~# hostname uts-namespace root@linuxias-VirtualBox:~# hostname uts-namespace root@linuxias-VirtualBox:~# cat /proc/sys/kernel/hostname uts-namespace root@linuxias-VirtualBox:~# 새로운 터미널 세션을 생성하여 hostname을 확인해봅니다. hostname이 설정 전의 hostname임을 확인할 수 있습니다.  linuxias@linuxias-VirtualBox:~$ hostname linuxias-VirtualBox 참고자료 및 문헌  Konstantin Ivanov | Containerization with LXC linux manual page - namespace, hostname  "
},
{
	"uri": "https://linuxias.github.io/container/namespace/7.cgroup_namespace/",
	"title": "7. Cgroup Namespace",
	"tags": [],
	"description": "",
	"content": "cgroup namespace는 프로세스의 cgroups의 뷰를 가상화 합니다.\n각 cgroup 네임스페이스에는 고유한 cgroup 루트 디렉토리 세트가 있습니다. 그 루트 디렉토리는 /proc/[pid]/cgroup 파일의 해당 레코드에 표시되는 상대 위치의 베이스 위치입니다. clone(2) 또는 unshare(2) 시스템 콜에 CLONE_NEWCGROUP 플래그를 전달하여 새로운 cgroup namespace를 생성할 수 있습니다. 이렇게 생성된 namespace는 현재 cgroups 디렉토리가 새 namespace의 cgroup 루트 디렉토리가되는 새 cgroup namespace로 들어갑니다. 이 정책은 cgroup 버전 1,2 모두에 적용됩니다.\n/proc/[pid]/cgroup 을 확인하면 표시되는 각 레코드의 세 번째 필드에 표시된 경로 이름은 해당 cgroup 계층에 대한 읽기 프로세스의 루트 디렉토리에 상대적인 위치입니다.\ncat /proc/$$/cgroup 12:pids:/user.slice/user-1000.slice/session-2.scope 11:memory:/ 10:cpuset:/ 9:hugetlb:/ 8:blkio:/ 7:freezer:/ 6:cpu,cpuacct:/ 5:devices:/user.slice 4:perf_event:/ 3:net_cls,net_prio:/ 2:rdma:/ 1:name=systemd:/user.slice/user-1000.slice/session-2.scope 0::/user.slice/user-1000.slice/session-2.scope 만약 해당 프로세스의 cgroup 디렉토리가 읽은 프로세스의 cgroup namespace의 외부에 위치한다면 경로는 ../ 와 같이 cgroup 구조에서 상위 레벨로 표시될 것 입니다.\n"
},
{
	"uri": "https://linuxias.github.io/books/readyforprogramminginterview/",
	"title": "프로그래밍 면접 이렇게 준비한다",
	"tags": [],
	"description": "",
	"content": "목차\nCHAPTER 1 구직을 시작하기 전에\n너 자신을 알라\n시장을 알라\n팔릴 만한 능력을 계발하라\n일 제대로 해내기\n온라인 프로파일을 정돈하라\n요약\nCHAPTER 2 입사 지원 절차\n회사 선택 및 접촉\n면접 절차\n리크루터의 역할\n근무 조건 협상\n요약\nCHAPTER 3 전화 예비 면접\n전화 예비 면접의 이해\n전화 예비 면접 방법\n전화 예비 면접 문제\n요약\nCHAPTER 4 프로그래밍 문제 접근법\n절차\n문제 해결\n풀이 분석\n요약\nCHAPTER 5 연결 리스트\n왜 연결 리스트인가?\n연결 리스트의 종류\n기초적인 연결 리스트 연산\n연결 리스트 문제\n요약\nCHAPTER 6 트리와 그래프\n트리\n그래프\n트리 및 그래프 문제\n요약\nCHAPTER 7 배열과 문자열\n배열\n문자열\n배열과 문자열 문제\n요약\nCHAPTER 8 재귀 호출\n재귀 호출의 이해\n재귀 호출 문제\n요약\nCHAPTER 9 정렬\n정렬 알고리즘\n정렬 문제\n요약\nCHAPTER 10 동시성\n스레드 기본 개념\n동시성 문제\n철학자들의 저녁 식사\n요약\nCHAPTER 11 객체지향 프로그래밍\n기본 원리\n객체지향 프로그래밍 문제\n요약\nCHAPTER 12 디자인 패턴\n디자인 패턴이란 무엇인가?\n일반적인 디자인 패턴\n디자인 패턴 문제\n요약\nCHAPTER 13 데이터베이스\n데이터베이스의 기초\n데이터베이스 문제\n요약\nCHAPTER 14 그래픽스와 비트 조작\n그래픽스\n비트 조작\n그래픽스 문제\n비트 조작 문제\n요약\nCHAPTER 15 데이터 과학, 난수, 그리고 통계학\n확률과 통계\n인공지능과 기계학습\n난수 생성기\n데이터 과학, 난수, 통계 문제\n요약\nCHAPTER 16 카운팅, 측정 및 순서 관련 퍼즐\n퍼즐 공략법\n퍼즐 문제\n요약\nCHAPTER 17 그림 및 공간 퍼즐\n일단 그려보자\n그림 및 공간 퍼즐 문제\n요약\nCHAPTER 18 지식 기반 문제\n준비\n문제\n요약\nCHAPTER 19 기술과 무관한 질문\n왜 기술과 무관한 질문이 필요할까?\n질문\n요약\nAPPENDIX A 이력서\n기술 이력서\n이력서 예\n취업을 준비하는 대학생들 중 많은 학생분들이 어떻게 취업을 준비해야 하는지, 면접은 어떻게 진행이 되는지 모르는 경우가 많습니다. 특히 전공 지식을 요구하는 소프트웨어 지식 고나련 인터뷰는 어떻게 진행되는지, 어떤 질문이 나올지 막연하고, 두려움도 있습니다.\n특히 실무 경험이 없는 학생분들의 경우, 책과 학교 실습으로 배운 내용이 완전히 이해하지 못하는 경우도 많고 이해하고 있다고 한들 누군가가 질문을 했을 때 논리 정연하게 자신의 지식을 말하는 기술이 부족합니다. 위에 작성한 내용에 포함되지 않는 학생 분들도 분명 있겠지만, 소수일 거라 생각됩니다.\n학생 외에도 현업에 종사하는 개발자 분들과의 대화에서도 종종 느낍니다. 가끔 자신의 실력에 자신감있는 개발자분들을 뵐 때가 있습니다. 그때 이직에 대한 대화주제에서 누군가 면접 인터뷰 경험을 얘기하고 자신이 받은 질문을 공유하는 경우가 있습니다. 그 질문에 대해서 \u0026lsquo;쉽네요?\u0026rsquo; 라고 대답하시는 분들이 계십니다. 정말 그 분들은 쉬울수도 있지만 10명 중 9명 정도는 답변 부탁드린다고 했을 때 알고있는 지식을 논리 정연하게 설명하지는 못하는 경우가 많았습니다. 저는 자신이 아는 것과 누군가에게 설명하는 것은 명확하게 다르다고 생각합니다. 이 책을 보시려고 고민하는 분들이라면 취업 준비 중인 대학생 또는 이직을 준비하는 현업 개발자 분일거라 생각합니다. 만약 그렇다면 저자가 부탁하는 과정을 꼭 지키면 큰 도움이 될 것 같습니다.\n  문제를 읽은 다음 바로 책을 덮어놓고 직접 문제를 풀어본다.\n  문제를 풀다가 막히면 풀이를 읽어본다.\n  풀이를 읽다가 필요한 힌트가 나왔다 싶으면 다시 책을 덮고 문제를 풀어본다.\n  위 과정을 반복한다.\n  저는 위 저자의 부탁과 추가로 \u0026lsquo;생각을 정리하고, 직접 소리내어 답변해본다\u0026rsquo; 도 함께 해보셨으면 좋겠습니다. 저도 면접 경험이 4~5회 정도 있습니다. 준비를 하는 과정 중 가장 아쉬운 것이 왜 아는 걸 제대로 말하지 못하였나.. 라는 후회감이였습니다. 꼭 누군가에게 정확하게 설명할 수 있는 연습을 하셨으면 좋겠습니다.\n추가로 이 책은 가이드는 주나 여기 나오는 문제가 면접에 꼭 질문받을 거란 생각을 하시는 분은 없을거라 생각합니다. 특히 책에서는 다양한 분야를 다루기에 그 질문의 깊이가 깊지는 않습니다. 이 책은 분위기가 초급 난이도의 질문 방향, 요구하는 답변등을 정리하는 책으로는 좋습니다. 특히 취업 준비하는 대학생 분들은 꼭 읽으셨으면 좋겠습니다.\n이 책은 프로그래밍 면접에도 도움이 되지만 컴퓨터 공학 전공 기초에 대해서 한번 훑고 기억을 되살리는 목적으로도 좋습니다. 가벼운 마음으로 기본 소양을 되새긴다는 마음으로 읽으셔도 좋을 것 같습니다.\n오랜만에 도서 리뷰를 작성하니 주저리주저리 정리가 안되는 것 같네요. 읽어주셔서 감사합니다.\n"
},
{
	"uri": "https://linuxias.github.io/linux/compilelink/gcc_warning_option/",
	"title": "[gcc] Warning 옵션",
	"tags": [],
	"description": "",
	"content": "gcc 컴파일 옵션으로 많이 사용하는 -Wall , -Wextra 이외에 다양한 옵션들은 정리하고자 합니다.\n   옵션 설명 특이사항     -fstack-usage 컴파일러가 프로그램에 대한 스택 사용 정보를 함수 단위로 출력하도록 합니다. 함수의 이름, 바이트 수 등이 표기됩니다. x   -Wframe-larger-than={len} 함수 프레임의 크기가 len을 넘어가면 Warning이 출력합니다. x   -Wstrict-overflow=n -fstrict-overflow가 활성화 되어있는 경우에만 활성화됩니다. 컴파일러가 signed 오버플로우가 일어나지 않을거라 가정하고 최적화를 진행하는 경우에 Warning이 발생합니다. Wall에 포함 (-Wstrict-overflow=1)   -Wlogical-op 표현식에서 논리연산자의 사용에 대해 문제가 발생할 수 있는 경우 Warning을 발생합니다. x   -Wjump-misses-init goto문을 통해 변수 초기화 이전으로 분기하거나, 변수가 초기화된 이후로 분기하는 것을 Warning이 발생합니다. C, Objective-C only   -Wmissing-include-dirs 사용자 제공 include 디렉토리가 존재하지 않으면 Warning이 발생합니다. C/C++, Obj C/C++ only   -Wunused 여러 unused 옵션(unused-but-set-parament, unused-but-set-variable, unused-function, unused-label, unused-local-typedefs, unused-parameter, -no-unused-result, unused-variable, unused-value)을 한 번에 포함하는 옵션입니다. 사용되지 않는 함수 매개 변수에 대한 경고를 얻으려면 -Wextra -Wunused (-Wall implies -Wunused)를 지정하거나 -Wunused-parameter를 별도로 지정해야합니다 Wall에 -Wunused-function -Wunused-label -Wunused-value -Wunused-variable 옵션이 포함되어 있습니다.   -Wpacked-bitfield-compat 4.1, 4.2 및 4.3 계열의 GCC는 \u0026ldquo;char\u0026quot;유형의 비트 필드에서 \u0026ldquo;packed\u0026quot;속성을 무시합니다. GCC 4.4에서 그러한 필드의 오프셋이 변경되면 GCC에서 알려줍니다. Default enable   -Winvalid-pch precompile된 헤더가 검색 경로에서 찾았으나 사용하지 못하는 경우 Warning이 발생합니다. -   -Wstack-protector Stack smashing으로부터 보호되지 않는 경우 Warning이 발생합니다. Stack smashing protector(SSP) 기능은 -fstack-protector 옵션을 사용해야 합니다. SSP 는 함수 진입 시 스택에 return address와 frame pointer 정보를 저장할 때 이 정보를 보호하기 위해 (canary라고 부르는) 특정한 값을 기록해두고 함수에서 반환할 때 기록된 값이 변경되지 않았는지 검사하여 정보의 일관성을 관리합니다. 만약 악의적인 사용자가 buffer overflow 등의 공격을 통해 스택 내의 정보를 덮어쓰려면 canary 값을 먼저 덮어써야 하기 때문에 canary 값 만 보면 공격이 일어났는지를 알 수 있습니다. -fstack-proctector가 활성화 된 경우 활성화 됩니다.   -Wunused-variable 지역변수 또는 상수가아닌 정적변수가 사용되지 않을 때 Warning이 발생합니다. -Wunused , -Wall에 포함   -Wunused-value 명시적으로 사용되지 않은 결과를 계산하는 경우 Warning이 발생합니다. -Wunused , -Wall에 포함   -Wcast-qual 포인터를 형변환 할 때 기존 type qualifier가 사라지는 경우 경고해줍니다(const char_을 char_로 형변환) -   -Wconversion 묵시적으로 타입을 변환하는 상황에서 값이 바뀔 가능성이 있는 경우 경고해줍니다(int temp = 0.3 등) -   -Wsign-conversion 부호있는 정수 표현식을 부호없는 정수 변수에 할당하는 것과 같이 정수 값의 부호를 변경할 수있는 변환에 대해 Warning이 발생합니다. -Wconversion 옵션에 의해 활성화됩니다.   -Wbad-function-cast 함수 콜이 매칭할 수 없는 타입에 캐스팅된 경우 Warning이 발생합니다. -   -Wwrite-strings constant 스트링을 non-const char* 포인터에 복사하는 경우 Warning이 발생합니다. 컴파일 타임에 const string을 변경하려는 문제를 찾을 수 있습니다. -   -Wconversion-null NULL 과 non-pointer 타입간의 변환에 대해 Warning이 발생합니다. Default enable   -Wextra -Wall에 의해 활성화되지 않는 추가적인 Warning flags(-Wclobbered -Wempty-body -Wignored-qualifiers -Wmissing-field-initializers -Wmissing-parameter-type (C only) -Wold-style-declaration (C only) -Woverride-init -Wsign-compare -Wtype-limits -Wuninitialized -Wunused-parameter (only with -Wunused or -Wall) -Wunused-but-set-parameter (only with -Wunused or -Wall))를 활성화합니다. -   -Wpacked 구조체에 packed 속성이 주어졌으나, 해당 레이아웃이나 크기에 영향이 없는 경우 Warning이 발생합니다. 이런 구조체는 아주 작은 이득을 위해 잘못 정렬될 수도 있습니다. -   -Wredundant-decls 유효범위 내에 동일한 오브젝트(변수 등)이 여러 번 선언된 경우 Warning이 발생합니다. -   -Waggregate-return 구조체 또는 공용체를 반환하는 함수를 선언하거나 호출 시 Warning이 발생합니다. 거의 사용하지 않는 Warning.. ANSI C 표준에 맞추기 위해 사용하나.. 흠,   -Wpointer-arith void의 크기나 함수의 크기를 갖고 연산(+/- 등)을 하는 경우 Warning이 발생합니다. -   -Wswitch-default switch 문에서 default case가 존재하지 않는 경우 Warning이 발생합니다. -   -Wundef 정의되지 않는 식별자가 #if, #endif 구문에서 사용된 경우 Warning이 발생합니다 -   -Wstrict-prototype 함수가 인자 형을 명시하지 않고 선언, 정의된 경우 Warning이 발생합니다. 즉, void test()와 같이 ()로 인자를 비워둔 경우 발생합니다. -   -Wfloat-equal 부동소수점 값이 ==, != 등의 등호로 비교된 경우 Warning이 발생합니다. -   -Wformat-y2k 2자리 연도를 출력하는 strftime()에 대해 Warning이 발생합니다. -   -Wshift-count-overflow Shift 연산이 타입의 크기와 같거나 큰 경우 Warning이 발생합니다. Default enable   -Wswitch-bool switch문이 boolean 타입의 인덱스를 가지는 경우 Warning이 발생합니다.    -Wno-conversion-null NULL과 non-pointer 타입 간의 변환에 대해 Warning이 발생하지 않도록 합니다. -Wconversion-null이 Default입니다.   -Wnested-externs extern 선언이 함수 안에 존재하는 경우 Warning이 발생합니다. -   -Wvarargs va_start와 같은 가변인자를 처리하는데 사용된 매크로의 의심스러운 사용에 대해 Warning이 발생합니다. Default enable   -Wunsuffixed-float-constants 접미사가 없는 부동상수에 대해 Warning이 발생합니다. -   -Wswitch-enum switch문에서 index로 enum을 사용한 경우에 enum의 멤버와 case의 수가 맞지 않을 때 Warning이 발생합니다. -   -Wshadow 지역변수가 다른 지역변수, 매개변수 등(shadow) 덮는 경우 Warning이 발생합니다.    -Wunreachable-code 어떠한 경우에도 실행할 수 없는 코드 라인이 존재하는 경우 Warning이 발생합니다. gcc 4.4 이상에서 제거됨   -Winline inline으로 선언된 함수가 inline이 불가능 경우 Warning이 발생합니다.    -funroll-loops for()와 같은 루프문을 풀어서 최적화 해주는 옵션으로, 코드를 크게 만들어주며 수행속도가 빨라질수도 아닐수도 있습니다.     감사합니다.\n"
},
{
	"uri": "https://linuxias.github.io/linux/compilelink/gcc_specific_attribute/",
	"title": "[gcc] 최적화 속성 사용하기",
	"tags": [],
	"description": "",
	"content": "gcc를 컴파일러로 사용할 시 -O2, -O3와 같은 최적화 옵션을 자주 사용하게 됩니다.\n특별한 경우에 특정 함수나 코드 구간에 대해서 특정 최적화 단계를 적용하고 싶다면 아래와 같이 진행합니다.\n함수에 최적화 적용하기 void __attribute__((optimize(\u0026#34;O0\u0026#34;))) func(void) { } 코드 범위에 최적화 적용하기 #pragma GCC push_options#pragma GCC optimize (\u0026#34;O0\u0026#34;) //Write your code  #pragma GCC pop_options감사합니다.\n"
},
{
	"uri": "https://linuxias.github.io/linux/compilelink/staticliblink/",
	"title": "정적 라이브러리 링크",
	"tags": [],
	"description": "",
	"content": "라이브러리 중 정적 라이브러리(static library)를 사용하는 경우가 종종 있다. 그리고 해당 라이브러리가 또 다른 (static library)를 Link 하는 경우가 있다. 이럴 때 문제가 발생하게 된다. 아래와 같이 어플리케이션이 필요로 하는 정적 라이브러리를 링크하게 되는데, 해당 라이브러리가 다른 정적 라이브러리를 링크하게 되는 경우이다.\nApplication \u0026ndash;\u0026gt; Static library 1 \u0026ndash;\u0026gt; Static library 2\nApplication은 Static library 1의 존재만 알 뿐 2의 존재는 알지도, 알 필요도 없다.\npkg-config를 이용한 경우 pc 파일에 정의 아래 libpalosalodp 의 pc.in 파일이다.\n# Package Information for pkg-config prefix=@prefix@ exec_prefix=${prefix} libdir=${exec_prefix}/lib includedir=${prefix}/include/ Name: libtest Description: test library Version: 0.0.1 Requires.private: libtest_internal \u0026gt;= 0.0.1 Libs: -L${libdir} -ltest Cflags: -I${includedir} \\  -I${includedir}/Include Requires.private 에서 libodp_internal_${sdktype} 에 대한 필요 정보를 명시하고, 다른 Application의 Makefile에서 pkg-config \u0026ndash;static 옵션을 붙여서 추가 시 해당 lib을 추가해준다.\nRequires.private 은 이 패키지에 필요한 패키지 목록을 나타내는 것으로 동적 링크된 실행 파일(static이 지정되지 않은 경우)에 대해 플래그 목록을 계산할 때 고려되지 않는다.\nRequires 사용하기 # Package Information for pkg-config prefix=@prefix@ exec_prefix=${prefix} libdir=${exec_prefix}/lib includedir=${prefix}/include/ Name: libtest Description: test library Version: 0.0.1 Requires: libtest_internal \u0026gt;= 0.0.1 Libs: -L${libdir} -ltest Cflags: -I${includedir} \\  -I${includedir}/Include Requires 옵션을 이용하여 포함시킨다.\nRequires와 Requires.private의 차이는 아래와 같다.\n  Requires: 패키지가 의존하여 사용하는 다른 패키지의 이름의 목록으로 공백으로 구분한다. 비교 연산자(=, \u0026lt;, \u0026gt;, \u0026lt;=, \u0026gt;=)를 사용하여 버전을 지정할 수도 있다.\n  Requires.private: 패키지가 의존하여 사용하는 다른 패키지의 이름의 목록으로 공백으로 구분한다. 단 Requires와 다르게 패키지 안에서만 사용하며 이 패키지를 가져다가 사용하는 애플리케이션에는 사용할 필요 없을 패키지를 나열한다. 버전을 지정하는 형식은 Requires와 동일하다.\n  하지만 정적 라이브러리를 링크하고 있는 상황이기 때문에, Requires를 사용하던지 Application은 pkg-config 에서 \u0026ndash;static 을 사용해야만 Requires.private에 정의된 패키지를 사용할 수 있다.\n"
},
{
	"uri": "https://linuxias.github.io/",
	"title": "Developer&#39;s Delight",
	"tags": [],
	"description": "",
	"content": "Developer's Delight Seungha Son   Samsung Electronics Software Engineer\n  Expert knowledge and hands-on experience of system programming, application developing, debugging and profiling and optimization based linux.\n  Programming skills in C (advanace level), and C++, Java, Python, Shell script (Intermediate level)\n  Interested in open-source, system architecture\n  "
},
{
	"uri": "https://linuxias.github.io/machinelearning/bdi_architect/",
	"title": "[Agent] BDI Architecture",
	"tags": [],
	"description": "",
	"content": "Belief - Desire - Intention Architect BDI Architect는 Software Agent 분야에서 자주 사용되었던 구조입니다. 이 구조의 이름인 BDI 는 3가지 단어 입니다. Belief, Desire, Intention 이 3가지 단어의 앞자리를 따서 만들어졌습니다. 그럼 3가지 단어가 이 구조의 큰 요소일 텐데 구조를 정리해 가며 설명드리겠습니다.\nBDI Architect는 목표를 이루기 위해 순간, 순간 행해야할 행위를 결정하는 의사결정 프로세스입니다. BDI 구조는 reactive behavior와 goal-directed behavior가 조화를 이루는 구조로써 Agent는 그 목표를 달성하기 위해 최선을 다하면서도 그 목표가 여전히 유효한지, 달성할 수 있는지에 대해 계속해서 확인하는 과정을 거치게 됩니다.\nBDI agent는 두 개의 중요한 프로세스를 사용합니다. Deliberations와 Means-ends reasoning인데요, Deliberation은 우리가 달성하기 원하는 목표가 무엇인지 결정하는 프로세스이며 Means-ends reasoning은 어떻게 우리가 그것을 달성할지에 대해 결정하는 것입니다. 이름은 어려운데 결국 어떤 목표를 어떻게 달성해야 할지에 대한 것을 프로세스를 나눠놓은 것이라 생각하시면 편합니다. 어떤 목표를 세우고 어떻게 달성하지에 대해 BDI에서는 3가지 개념을 이용해 정의해 놓았습니다. 가장 처음 말씀드린 BDI 입니다. 하나의 예시를 개념 별로 들어보겠습니다.\n  B (Beilive) : 만약 내가 공부를 열심히 한다면 이번 시험을 패스할 수 있습니다.\n  D (Desire) : 이번 시험을 통과하길 바랍니다.\n  I (Intend) : 나는 공부를 열심히 할겁니다!!\n  사람이 무엇인가 목표를 세우고, 목표를 이루기 위해 어떻게 해야할지 결정하는 과정과 유사한 것 같습니다. BDI가 이 구조에서 어떤 역할을 하는지 정리해야 할 것 같습니다. Belief는 Agent가 가진 믿음, 정보입니다. 여기서 이 정보가 100% True일 필요는 없으며 Agent가 어떠한 정보를 가지고 있다라는 것이 중요한 점이라고 생각됩니다. 조금 의아하시겠지만, 아래서 더 자세히 설명드리겠습니다. Desire은 목표입니다. 이번 시험에서 통과하는게 목표가 되겠네요. 그리고 Intend는 목표를 이루기 위해 행동하는 방안입니다.\n위에서 너무 나불나불 한 것 같아서 예시를 한번 들어보겠습니다. 예시는 호텔 매니저로 하겠습니다. 여러분들이 호텔 매니저라면 B, D, I 가 무엇이 되어야 할지 한번 생각해보시죠. 먼저 호텔 매니저는 룸 관리를 해야 할 것 입니다. 예약 상태나 현재 어느 객실에 고객이 숙박하고 있는지 등의 관리가 필요할 것입니다. 저는 아래와 같이 정리하였습니다.\n  B (Beilive) : 룸 상태와 스케쥴 정보(예약 상태, 현재 숙박 여부 등)를 알고 있어야합니다.\n  D (Desire) : 고객 문의에 대해 정확한 룸 상태와 예약 여부등을 알려주고 싶습니다.\n  I (Intend) : 룸 상태가 청결하며 현재 예약 여부 및 숙박 상태를 정리해 예약을 받아야 합니다.\n  뭔가 정리가 잘 안된 것 같지만.. 얼추 이해가 되시나요? 더 좋은 의견 있으시면 댓글로 부탁드려요 :D\n계속해서 설명드리겠습니다. Intention의 역할에 관한 것입니다. Intention은 목표를 이루기 위한 행위라고 하였습니다. 어떻게 달성할지에 대한 행위라고 했죠. 만약 이 행위가 실패한다면 또 다른 방법으로 목표를 달성하기 위해 행동해야 할 것 입니다. 이 행위는 목표를 달성하기 위해 쉽게 포기해서는 안될 것 입니다. 그렇다고 무조건적으로 유지되는 것도 아니죠. 만약 더 좋은 정보로 인해 목표 달성에 좋아진다면 행위가 변경될 수 있습니다. 아까 공부에서 열심히 공부한다도 좋겠지만, 시험 감독이 없다 라는 정보가 있다면(잘못된 정보라 하더라도) 컨닝을 한다 라는 행위가 발생할 수 있다는 것이죠. 최종 목표는 시험을 통과하는 것이닌깐요. 이러한 Intention은 추후 practical reasoning을 기반으로 Belief에 영향을 주게됩니다.\n그럼 얼마나 자주 현재 진행하고 있는 Intention이 재검토 될까요? 현재 결정된 Intention이 목표 달성에 불가능한 행위인데도 불구하고 계속 진행한다면 잘못된 것일테니 분명 재검토는 필요합니다. 공부를 계속해도 안된다면 컨닝으로 방향을 틀어서라도 목표를 달성해야죠!! (물론 잘못된 행동이지만요..) 재고의 빈도에 대해서는 2가지 Agent로 나뉠 수 있습니다. Bold agent와 Cautious agent인데요. 먼저 Bold agent는 대범한 에이전트입니다. 거의 재고하는 일이 없는 녀석이죠. 더이상 불가능하거나 달성할 이유가 없더라도 우직하게 수행해 나가는 에이전트입니다. 다른 하나는 Cautious agent입니다. 조심스러운 녀석으로 Intentions 수행위해 계속하여 시간을 투자해서 끊임없이 재고함으로써 결국 목표를 달성하지 못하는 에이전트입니다. Intention을 재고하는 가장 좋은 방법은 Bold도 Cautious도 아닌 둘의 적절한 균형이 필요할 것 같습니다. Agent는 항상 동일한 환경과 동일한 외부자극을 받는게 아니니 환경과 외부자극에 대해 현재 Intention을 검토할 필요가 있습니다. The rate of world change(r) 라는 값을 이용하게 됩니다. r이 낮다면 bold agents 쪽으로 더욱 강화하면 좋습니다. 외부 환경 변화가 적은편이니 현재 Intention을 유지해 나가면 좋죠, 반대로 r이 높다면 Cautious agent 쪽에 중점을 두면 좋습니다. 새로운 변화와 자극은 기회가 될 수 있고 어떠한 이점이 있는지 검토가 필요하닌깐요. r에 변화에 따라 어느 방향으로 나아갈 지 결정된다면 좋을 것 같네요.\n그럼 이제 BDI Architecture의 큰 그림을 살펴보겠습니다.\n  A belief revision function (brf)\n- 외부환경, 자극, 입력과 현재 Beliefs를 이용해 정보를 표현합니다.\n  A set of current beliefs\n- 현재 Beliefs의 집합\n  An option generation function\n- 환경 및 현재 Intention들 그리고 Belief 들을 기반으로 할 수 있는 Options들을 결정하게 됩니다.\n  A set of current desires (options)\n- 현재 Desire들의 집합입니다.   A filter function\n- Intentions을 표현하기 위한 녀석으로 Deliberation Process를 나타냅니다. 이때 현재 Belief, Desire, Intention 모두를 사용합니다.\n  A set of current intentions\n- 현재 Intection들의 집합\n  An action selection function\n- 현재 Intention들을 기반으로 수행할 Action을 선택합니다.\n  BDI Architecture에 대해 간단하게 정리해보았습니다. Belief, Desire, Intention을 기반으로 입력, 외부환경, 자극에 대해 최종적으로 목표를 이루기 위한 Output이 결정되는 모델이라는 점에 주목하면 좋을 것 같네요. 부족한 점이나 수정해야 될 부분이 있다면 언제든지 댓글 부탁드립니다. 감사합니다.\n"
},
{
	"uri": "https://linuxias.github.io/machinelearning/agent_communication/",
	"title": "[Agent] Communication",
	"tags": [],
	"description": "",
	"content": "Communication between agents 에이전트들간의 커뮤니케이션을 알아보기 이전에 한 가지 용어를 정리하고자 합니다. \u0026lsquo;Speech Act\u0026rsquo; 란 용어입니다. Speech Act는 한국어로 언어행위론 이라고 정의할 수 있습니다. 언어행위론이란 언어를 통해 이루어지는 행위를 말합니다. 나는 너를 용서한다 라고는 말하면 말로써 행위가 표현되듯 언어가 어떤 영향을 주는지에 대해 초점이 맞춰져 있습니다. 명령, 요구 등으로 나뉠 수 있죠.\n그럼 이제 커뮤니케이션에 대해 정리해보겠습니다. 예를 들어서 살펴보죠. 개인비서 에이전트가 있다고 합니다. 이 에이전트에게 여러분은 김군과 저녁 약속을 잡아달라고 요청합니다. 그럼 이 에이전트를 어떠한 것들이 필요할까요? 간단히 생각해 보세요. 김군의 저녁 일정들이 필요할 것 같네요. 그리고 약속을 위한 약속장소의 정보도 필요할 것 같습니다. 약속을 잡기위한 목표를 이루기 위해 MAS가 필요할 것 같네요. 약속을 잡기 위한 전체 흐름을 살펴보죠.\n먼저 DA에게 김군 일정을 관리하는 에이전트가 누군지 문의합니다. 김군의 에이전트를 모르니 정보를 알아야겠죠. DA는 모든 정보를 관리하는 중계 에이전트라고 생각하시면 됩니다. DA에서 전달받은 김군 에이전트의 정보를 이용해 약속 가능한 일정을 문의하고 답변받은 리스트 중 선택한 요일을 알려줘 약속을 최종적으로 잡게되는 흐름입니다. 생각보다 단순하죠? 위 그림에서 저렇게 에이전트간 커뮤니케이션를 어떻게 이루어지는지에 대해 살펴보게 될 것 입니다. 여기서 목표는 김군과 약속을 잡는 것으로 김군 캘린더에 나의 시간을 할당받는 것입니다. 목표를 이루기 위한 Intention으로 김군의 캘린더 에이전트를 찾는 것도 있을테구요. 그 Intention은 Speech act로 이루어 집니다. DA에게 누가 김군 캘린더를 관리하니? 란 Speech가 행위로 연결되죠.\n에이전트간 커뮤니케이션을 위한 언어가 정의되어 있습니다. Agent Communication Language입니다. ACL은 다른 위치와 행동을 하는 에이전트들 간의 커뮤니케이션을 할 수 있도록 해주고 각 에이전트가 가진 정보와 지식을 교환할 수 있도록 지원해주는 역할을 합니다. 사람의 언어와 똑같은거죠. 처음엔 커뮤니케이션을 Remote Procedure Calls나 Remote Method Invocation과 같은 방식을 사용했습니다. 하지만 사람과 유사한 방식을 만들고자 노력하였고 유연하면서도 요청이나 역할을 다룰수 있는 방식으로 진화하며 만들어졌습니다.\nMAS에서 커뮤니케이션은 가장 처음 설명한 Speech act 이론에서 영감을 받아 만들어졌습니다. 사람들이 매우매우 Goal과 Intention을 달성하기 위해 어떻게 언어를 사용하였는지 확인하였고 사람과 가장 유사한 방식이길 바랬습니다. 일반적으로 Speech Act는 2가지 요소로 나눠볼 수 있습니다. Performative verb(실행자)와 Propositional content(상태)입니다. 실행자는 Request, Inform 등을 행하게되고, Content는 그 정보가 되는 것이죠. 단순 예시를 들어보겠습니다.\nSpeech Act에 따라 Performative는 문에 대한 요청이나 정보, 문의등이 되고 Content는 그에 따른 상태표현이 됩니다. 이렇게 Speech act는 물리적인 행위로서 간주될 수 있습니다. 행위는 선행조건(precondition) 또는 후행조건(postcondition)으로 특화될 수 있습니다. 만약 A가 B에서 t를 요청한 경우에 대해 선행 조건은 \u0026lsquo;A는 B가 t를 할 수 있다고 믿는다.\u0026rsquo; , \u0026lsquo;A는 B가 t를 할 수 있다는걸 B가 믿는다는걸 믿는다\u0026rsquo; , \u0026lsquo;A는 A가 t를 원한다고 믿는다\u0026rsquo; 는 조건이 될 수 있다. 후행조건은 \u0026lsquo;A가 t를 원한다고 A가 믿는걸 B는 믿는다\u0026rsquo; 라는 의미입니다. 음, 설명해 놓고나니 무슨 말인지 잘 모르겠네요. 다음에 좀 더 좋은 예시가 있다면 수정하겠습니다.\nSpeech Act를 기반으로 제작된 ACL은 다른 에이전트들과 효율적으로 커뮤니케이션하거나 지식 정보를 교환할 수 있도록 해줍니다. ACL의 3가지 측면(Syntax, Semantics, Pragmatics)에서 바라보면 Syntax는 어떻게 커뮤니케이션의 실볼들이 구조화되는지하는 것이며, Semantic은 심볼이 나타내는 것이 무엇인지, Pragmatics는 심볼을 어떻게 이해하는지에 관한 관점입니다. ACL로서 대표적인 언어 중 하나로 KQML이 있습니다. KQML은 (Knowledge Query and Manipulation Language)의 약자인데요, 에이전트 간의 지식과 정보의 교환을 위해 설계된 통신 언어입니다. 일반적으로 질문, 선언, 신뢰, 요구, 획득, 묘사, 제공 등과 같은 정보에 대한 상태를 교환하는 데 사용되는 일종의 메시지 포멧이라고 보시면 됩니다. KQML의 카테고리는 아래와 같습니다.\nKQML에는 송신자, 수신자, 그들의 주소 등 통신과 관련된 요소들을 나열한 통신 계층과 수행어로써 메시지의 성질을 정의하는 메세지 계층, 실제적인 메시지가 들어 있는 내용 계층이 있습니다. 또한 커뮤니케이션 프로토콜을 만들기 위해 도와주는 Facilitator도 포함하고 있습니다. Facilitator는 유용한 커뮤니케이션 서비스를 제공하기 위핸 에이전트들의 특별한 그룹입니다. 여기서 말하는 유용한 커뮤니케이션 서비스란 서비스 네임등록을 유지하거나 메시지를 서비스들에게 전달하거나 Content 기반의 메시지들을 Routing 하는 기능, 찾고자하는 자와 정보를 가진 에이전트를 매칭시켜주거나 하는 역할을 말합니다. Facilitator의 예시를 한번 보겠습니다.\nA, B란 에이전트가 있고 F란 이름의 Facilitator가 있다고 가정합니다.  A-B간 Point-to-Point Protocol  graph LR; A[A] --\u0026gt; |ask X| B[B] B --\u0026gt; |tell X|A[A] Point-to-point protocol에선 A가 B에게 X에 대한 정보를 얻기 위해 ask(X)를 다이렉트로 하고 B또한 A에게 tell(X)로 받아들입니다.\nUsing the subscribe performative  graph LR; A[A] --\u0026gt; |subscribe ask X| F[F] B --\u0026gt; |tell X|F F --\u0026gt; |tell X|A A -\u0026gt; F : subscribe(ask(X)) A가 F에게 ask(X)에 대한 구독을 요청합니다. B- \u0026gt; F : tell(X) B가 F에게 X에 대한 정보를 알립니다. F -\u0026gt; A : tell(X) F가 A에게 X의 정보를 알려줍니다. 위 방식은 F를 통해 구독을 요청하고 정보를 F를 통해 받는 방식입니다. A, B간에는 어떠한 경우도 다이렉트로 커뮤니케이션 하는 일이 없습니다.\nUsing the broker Performative  graph LR; A[A] --\u0026gt; |broker ask X| F[F] B --\u0026gt; |advertise ask X|F[F] F --\u0026gt; |tell X| A[A] F --\u0026gt; |ask X| B[B] A -\u0026gt; F : broker(ask(X)) A가 F에서 X를 해결해줄 에이전트를 찾음. B -\u0026gt; F : advertise(ask(X)) B는 F에게 X를 처리할 수 있다고 자신을 광고하고 알림 F -\u0026gt; A : tell(X) and F -\u0026gt; B : ask(X) 위 구조는 F가 브로커 역할을 하여 A와 B의 요청을 각각 처리해 줍니다.\nUsing the recruit performative  graph LR; A[A] --\u0026gt; |recruit tell X| F[F] B --\u0026gt; |tell X| A[A] B --\u0026gt; |advertise ask X|F[F] F --\u0026gt; |ask X| B[B] A -\u0026gt; F : recruit(tell(X)) tell(X)를 처리해줄 수 있는 적절한 에이전트를 찾아달라고 요청합니다. B -\u0026gt; F : advertise(ask(X)) B는 F에게 ask(X)를 자신이 처리할 수 있는 에이전트라고 광고합니다. F -\u0026gt; B : ask(X) A에게 요청한 ask(X)에 적절한 B 에이전트를 찾았고 B에게 ask(X)를 보낸다. B -\u0026gt; A : tell(X) F를 거치지 않고 B가 A에게 다이렉트로 응답합니다.\nUsing the recommend performative  graph LR; A[A] --\u0026gt; |recommend ask X| F[F] B --\u0026gt; |recommend advertise ask X|F[F] F --\u0026gt; |reply B| A[A] A --\u0026gt; |ask X| B[B] B --\u0026gt; |tell X| A[A] A -\u0026gt; F : recommend(ask(X)) A가 F에게 ask(X)를 처리해줄 수 있는 에이전트를 추천해 달라고 요청한다. B -\u0026gt; F : advertise(ask(X)) B는 F에게 ask(X)를 처리해 줄 수 있는 에이전트라고 광고한다. F -\u0026gt; A : reply(B) F는 A에게 B가 알맞은 에이전트라고 알려준다. A -\u0026gt; B : ask(X) B -\u0026gt; A : tell(X)\n위와 같이 A,B란 에이전트와 F (Facilitator)의 관계에서의 예시를 살펴보았습니다. 조금 이해가 되시나요?\n그럼 KQML이 아닌 FIPA ACL에 대해 정리해보겠습니다. FIPA는 The Foundation for Intelligent Physical Agents의 약자입니다. FIPA의 목적은 에이전트 기반의 어플리케이션, 서비스들의 성공을 위해 만들어진 곳입니다. 공공의 이익을 위한 집단입니다. FIPA가 집단이면 FIPA ACL은 FIPA에서 만든 ACL이겠죠? FIPA ACL은 KQML과 매우 유사합니다. Performative도 존재하구도 Content도 존재하구요. 메시지 구조는 봉투 형태를 띄고 있습니다. 메시지 내용은 봉수 내에 들어있고 봉투에는 전송 정보만 작성되어 있는 형태입니다. FIPA ACL에서 기본적인 Performative는 Inform 과 Request입니다. Inform과 Request의 의미는 두 부분으로 정의할 수 있습니다. Precondition(사전조건, speech act가 성공하기 위해 진실이여야만 하는 것들) 과 Rational effect(합리적 영향, 그 메신지의 발신자가 가져오길 바라는 것)입니다. KQML과 FIPA ACL을 잠시 비료해 보죠.\nKQML과 FIPA ACL의 유사한 점은 Outer Language(Performative)와 Inner Language(Content)가 분리되어 있으며 어떤 content language도 허용한다는 점입니다. 차이점은 KQML은 Performative를 FIPA ACL은 communicative act를 좀 더 중점에 두고 있다는 것과 다른 프레임워크 사용으로 KQML과 FIPA Performative 간 정확한 매핑이나 전송이 불가능하며 KQML은 facilitator를 지원하지만 FIPA ACL는 그렇지 않다는 점이죠. KQML은 무조건 중계자가 있어야 함으로 중앙 집중식 구조가 되며, Facilitator에 로드가 크다는 단점이 있을 수 있습니다.\n에이전트 간 커뮤니케이션하기 위한 방법으로 Speech Act를 기반으로 만들어진 ACL과 ACL 중 가장 많이 사용되는 KQML, FIPA ACL에 대해 정리해보았습니다.\n긴 글 읽어주셔서 감사합니다. 수정되어야 할 부분이나 질문있으시면 댓글로 언제든지 부탁드립니다.\n"
},
{
	"uri": "https://linuxias.github.io/machinelearning/agent_mas/",
	"title": "[Agent] MAS (Multi-agent System)",
	"tags": [],
	"description": "",
	"content": "MAS (Multi-agent System) 현재 세계의 시스템에선 하나의 agent로는 모든 처리를 할 수 없습니다. 그래서 각각의 기능을 담당하는 여러 agent를 생성하여 협업 또는 조율하게 만드는 방법을 사용하기도 합니다. 이번 글에서는 MAS, Multi-agent System에 대해 정리해보겠습니다.\nMulti-agent System (지금부턴 MAS라 칭하겠습니다.)은 시스템 내에 여러 agent를 가지고 있는 시스템입니다. 각 agent 간 커뮤니케이션을 통해 상호작용을 하게 되고, 서로 다른 작업을 하기에 \u0026ldquo;spheres of influence\u0026rdquo; 라고 불리는 자신만의 환경 영역을 가지고 있습니다. 즉 변화하는 환경에 대해 영향을 받거나 주는 환경이 다를 수 있습니다. 분산 AI 측면에서 MAS를 살펴보면 하나의 Agent로는 해결하기 어려운 문제들을 여러 Agent가 서로 보유한 다른 정보들과 능력을 이용하여 해결하게 됩니다. 문제의 해를 찾기위해 함께 동작하게 되며 서로간은 루즈하게 결합되어 있습니다. 각각의 agent는 문제 해결을 위해 불완전한 기능들을 가지고 있습니다. 하나의 agent만으로는 문제 해결이 불가능하단 얘기이죠. 또한 MAS는 중계자, 전체 시스템을 컨트롤하는 녀석이 별도로 존재하지 않고 각 데이터도 agent들에게 분산되어 있기에 탈 중앙화 시스템입니다. 이러한 탈 중앙화로 보안성과 안정성이 확보되었습니다. 개별적으로 agent가 동작할 수 있기에 비동기적으로 동작되는 시스템입니다.\nMAS에서 agent가 모두 협렵하는 방식으로 구성되는 건 아닙니다. agent들이 서로 경쟁하도록 만들수도 있죠. 문제해결을 위한 방법 중 하나인데요. 하나의 문제를 협력하여 해결하는게 아니라 서로 경쟁시킴으로써 가장 좋은 해를 구할 수 있게 됩니다. 뭐가 더 좋은지는 상황에 따라 다르겠지요. 좀 더 자세히 Cooperative MAS와 Competitive of Self-interested MAS에 대해 정리해 보죠 Cooperative MAS  대표적인 MAS domain입니다. 분산 문제 해결로 각 agent는 자율성이 낮습니다. 협력과 팀웍을 위한 모델로써 각자 새우는 계획이 다릅니다. 다른 동작을 하기 때문이죠.  Competitie of Self-interested MAS  분산된 합리성입니다. 투표나 경쟁하는 시스템입니다. 협상 등에 자주 사용되는 모델입니다.  MAS의 전통적인 모델은 서버-클라이언트 모델이였습니다. 서버-클라이언트 간 커뮤니케이션 또한 매우 Low-level의 메시지들을 사용하였으며 동기적으로 동작하였습니다. 클라이언트가 요청하면 서버가 응답하는 구조였죠. 하지만 지금은 여러 Agents들이 Peer-to-Peer로 연결되어 있으며 서버라는 개념이 없습니다. 캡슐화된 메시징 기법으로 보안성도 강화화였으며 High-level의 메시지 프로토콜들을 사용하게 되었습니다. MAS를 연구하는 사람들은 Agent간 커뮤니케이션을 매우 중요하게 생각하였습니다. 그래서 멀티 시스템에 맞는 Communication Language, Interaction Protocol 들을 개발하게 되었지요. 개발에 영감을 준건 곤충의 군집생활입니다. 이런 MAS와 같은 시스템에 좋은 본보기가 될 수 있죠. 공통의 목적을 위해 어떻게 군집활동을 하고 어떻게 커뮤니케이션하며 어떠한 룰을 정하는가와 같은 점을 토대로 만들었습니다.\n그럼 유명한 MAS 몇개 모델만 간단히 정리해보겠습니다. Object Manager Group (OMG) 일반적인 패턴들과 정책들을 사용하여 협업하는 에이전트들과 에이전시들로 구성되어 있습니다. 에이전트는 능력, 상호협력의 타입으로 특정지어지며 에이전스들은 에이전트들의 동시 실행, 보안 등을 지원하는 녀석입니다. FIPA(Foundation for Intelligent Physical Agents)\u0026lsquo;s Model Agents, Agent Platform, Directory Facilitator, Agent Management System, Agent Communication Channel, Agent Communication Language 로 구성되어 있는 모델입니다.\nKAoS'S Model 에이전트를 위한 개방형 분산 아키텍쳐입니다. 다양한 에이전트 구현들을 정의하고 있으며 에이전트 간 커뮤니케이션을 위해 대화 정책을 사용합니다.\nOAA Model User Interface, NL to ICL, Application, Meta에이전트들과 이 에이전트들이 커뮤니케이션을 하는 Facilitator 에이전트로 구성되어 있습니다. 어플리케이션은 API를 통해 Application Agent를 사용하게 되고 User Interface 에이전트는 사용자의 요청등을 처리하게 됩니다. 각 에이전트간의 커뮤니케이션은 모두 Facilitator 에이전트가 중재하게 되는 구조입니다.\nGeneral Magic's Model 전자상거래를 위한 금융 에이전트로 시작되었습니다. Zeus (MAS development toolkil) MAS 개발을 위한 개발도구 입니다.\nMAS의 각 Agent들은 서로 조직을 이루기 위해 다른 기능을 가지고 있는데요, 그 기능들 사이의 종속성들을 관리하는 과정을 Coordination이라고 합니다. Coordination을 통해 순서나 병렬적 수행들을 관리할 수 있죠. 이런 Coordination은 Activity, Conversation, Implementation 3가지 측면에서 살펴보겠습니다.   Activity\n실행해야 할 행위가 무엇인지 언제 실행되어야 하는지에 대한 것입니다. 분산 태스크에 대해 Statechart나 Flowchart, process algebra 등으로 표현할 수 있습니다.\n  Conversation (State)\n협력하는 개체들간의 대화 구조가 무엇인지에 대한 것입니다. FSM, Petri-Nets, State Transition Diagram 등이 있습니다.\n  Implementation\n어떻게 분산 시스템을 구현할지 협력하는 행위들의 요소들이 어디에 위치해야 할지에 대한 것입니다.\n  또한 MAS는 기본 협업 메커니즘(Coordination mechanism)에 기초한 지식을 교환하여 단일 목표에 도달하기 위해 에이전트 간 협업을 합니다. 대표적인 예시가 CNP(Contract Net protocol)입니다. CNP는 4개의 Phase로 구성되어 있습니다.\n  Phase 1 - Task Announcement\n계약 에이전트가 태스크를 수행할 능력이 있는 에이전트들이 나타나도록 브로드캐스팅합니다. 그 태스크를 수행하기 위한 잠재적 후보자들을 평가하기 위함입니다.\n  Phase 2 - Submission of Bids / Proposal\n요구를 만족하고 태스크를 수행할 능력이 있는 에이전트들은 계약 에이전트에게 입찰을 하게 됩니다. 본인이 해당 태스크를 처리할 수 있도록 말이죠.\n  Phase 3 - Selection\n계약 에이전트는 받은 입찰들을 기반으로 최종 후보자를 선택하는 과정을 진행합니다.\n  Phase 4 - Contract awarding\n계약 에이전트, 최종 선택된 에이전트간 계약이 성립되고 상호 커뮤니케이션을 위한 채널이 생성됩니다.\n  위와 같은 단계를 거쳐 Collaboration이 일어나게 됩니다. 일반 사회에서 일어나는 경매 시스템과 비슷한 것을 느끼시나요? 그에 맞춰서 이해하셔도 좋을 것 같습니다.\n이 글의 앞부분에서 MAS는 Cooperative와 Competitive 모델이 있다고 했습니다. Competitive보단 Cooperative가 많이 사용되는데 Competitive 모델을 디자인하는데 몇 가지 이슈를 확인해보겠습니다. 첫 번째 이슈는 Distributed Rationality입니다. Distributed Rationality는 Self-interested Agent 들이 샌드 박스에서 공정하게 경쟁하도록 유도하거나 강제하는 기술입니다. 모든 에이전트들의 의견을 취합하는 투표방식이나 모든 에이전트들이 얼마나 공정하게 기회를 부여받을지에 대한 경쟁등이 있습니다. 공정성, 안정성, 거짓말, 전역적으로 사용성을 높이기 위한 방안 등에 대한 이슈입니다. 두 번째 이슈는 Pareto optimality(파레토 효율성)입니다. Pareto Optimality는 [1]어떤 경제주체가 새로운 거래를 통해 예전보다 유리해지기 위해서는 반드시 다른 경제주체가 예전보다 불리해져야만 하는 자원배분상태를 의미합니다. 최적화를 위해서 단편적으로 보아서는 안되며 여러 측면에서 고려가 필요한 문제입니다. 마지막으로 Stability(안정성)입니다. 만약 어느 에이전트가 특정 전략을 가지고 다른 에이전트들의 행동과 관련없이 사용성을 항상 최대화 할 수 있다면 어떻까요? 다른 에이전트의 전략을 고려할 때 각 에이전트의 전략이 지역 최적인 경우 에이전트 전략 집합은 [2]내쉬 균형(게임이론의 개념으로서 각 참여자(Player)가 상대방의 전략을 주어진 것으로 보고 자신에게 최적인 전략을 선택할 때 그 결과가 균형을 이루는 최적 전략의 집합을 말한다)에 있습니다. 그렇게 되면 전략을 변경하려는 에이전트도 없을 것입니다. MAS를 어떤 플로우로 개발하는지 살펴보겠습니다.\n  특정 문제를 해결하기 위한 MAS 구성을 정의한다.\n  Coordination mechanism을 결정한다.\n  MAS를 구현하기 위한 프레임워크(Zeus 같은)를 선택한다.\n  MAS를 지원할 Collaborative mechanism을 구현한다.\n  Shared ontology를 구현한다.\n  각 태스크 에이전트를 구현한다.\n  중간자 에이전트를 커스터마이징 한다. (Facilitators, Mediators, Brokers, \u0026hellip;)\n  큰 그림부터 필요한 요소들을 하나하나 선택, 결정하고 구현하는 단계를 거칩니다.\n이러한 MAS는 다양한 곳에서 사용됩니다. 인터넷에서 정보검색을 하거나 보안 강화나 전자상거래의 쇼핑 에이전트들, 분산 신호처리 시스템 등에서 다양하게 사용됩니다.\n뭔가 주절주절 나열한 것 같습니다. 이해가 안되시는 부분이나 잘못된 부분은 언제든지 댓글로 남겨주세요. 감사합니다.\n[1] https://terms.naver.com/entry.nhn?docId=3437709\u0026amp;cid=58393\u0026amp;categoryId=58393\n[2] https://terms.naver.com/entry.nhn?docId=778808\u0026amp;cid=42085\u0026amp;categoryId=42085\n"
},
{
	"uri": "https://linuxias.github.io/machinelearning/agent_sw_agent_architecture/",
	"title": "[Agent] SW Agent Architecture",
	"tags": [],
	"description": "",
	"content": "소프트웨어 에이전트 아키텍쳐에 대해 정리해보겠습니다.\n에이전트 구조는 3개로 크게 나뉠 수 있습니다.\n  Deliberative : 의도적인, 신중한\n  Reactive : 반응하는\n  Hybrid : Deliberative + Reactive\n  용어 의미만 보아서 파악할 수 있는건 Hybrid밖에 없는 것 같네요. 하나씩 정리해보도록 하겠습니다.\nDeliberative Agents Deliberative Agents는 명확하게 표현되어 질 수 있는 실세계의 상징적 모델이며 Symbolic reasoning을 통해 결정을 만들어 나가는 에이전트입니다. Sense-plan-act 를 통한 문제 해결방식으로 Deliberative 구조로 BDI, GRATE*, HOMER, Shoham 등이 유명합니다. Deliberative는 Deductive reasoning agents와 Practical reasoning agents로 나뉘어져 있습니다. Deductive reasoning은 연역적 추론을 기반으로 한 Agent이며 Practical reasoning은 실용적 추론을 기반으로 한 Agent 입니다.\nDeliberative Agent는 아래와 같은 플로우를 가집니다.\nInput -\u0026gt; [ Sensors -\u0026gt; World Model -\u0026gt; Planner -\u0026gt; Plan Executor -\u0026gt; Effector ] -\u0026gt; Output\n입력에 대해 Sensing하고 Model에 대해 목표 달성을 위한 Plan을 세우게 됩니다. 이 때 Plan은 하나일 수도 있고 여러개 일 수도 있습니다. 그 중 목표달성을 위한 적절한 Plan을 선택하여 실행하게 되는 순서입니다.\nDeliberative Agents의 문제는 Performance와 Representation 문제가 있습니다. Performance는 환경이 급속하게 변화된다면 상징적 표현을 필요한 모든 정보로 변환하는데 시간 소모가 많습니다. Representation은 어떻게 세계 모델이 상직적으로 표현될 수 있는가와 그리고 결과를 유용하게 사용할 수 있도록 제 시간에 정보를 근거로 에이전트를 추론하는 방법에 대한 문제가 있습니다. 이렇게 느린 결과는 쓸모가 없을 뿐더러 실제 세계 모델은 매우 복잡하기에 심볼로만 처리하기엔 어려움이 많습니다.\nDeliberative Agents에는 Deductive Reasoning과 Practical Reasoning이 있다고 말씀드렸는데요, 이 둘에 대해 자세히 정리해 보겠습니다. 먼저 Deliberative Agent입니다. 연역적 추론을 기반으로하는 에이전트 인데요, 연역적 추론이란 전제들이 참이면 결론은 항상 참이라는 것이 보장되는 추론입니다. 에이전트가 어떻게 정리 이론을 이용해서 무엇을 하는지 결정해야하는가? 에 대한 질문을 던질 수 있는데요, 기본적인 아이디어는 주어진 상황에서 수행가능한 최고의 액션을 서술하는 이론을 인코딩하는 사용하는 것입니다. 뭔가 어렵네요. Deductive Reasoning은 매우 단순하고 논리적인 의미를 담고있습니다. 하지만 어떻게 어떻게 실세계의 정보를 심볼정보로 변경할 지, 추론에 대한 시간 복잡도는 어떨지 고민해봐야 할 것 같습니다.\n다음 Practical Reasoning입니다. Practical Reasoning은 행동에 대한 Reasoning입니다. Practical reasoning은 두 개의 activity로 구성되어 있는데요, Deliberation과 Means-ends reasoning입니다.\n  Deliberation (숙고, 신중함) : 달성하고자 하는 일의 상태가 무엇인지 결정하는 것\n  Means-ends reasoning (방법 목적 추론) : 일의 상태들을 달성하기 위해 어떻게 해야하는지 결정하는 것\n  어렵네요. Deliberation은 달성하고자 하는 일 자체의 상태이고, Means-ends reasoning은 일의 상태를 달성하기 위해 어떠한 과정을 결정해야 하는 것인가(?) 로 생각해보면 좋을 것 같습니다. Deliberation의 출력이 곧 Intentions입니다. Intentions이란 용어는 에이전트가 선택하고 실행해야할 일의 상태를 말합니다. Practical reasoning에서 중요한 역할을 하는 녀석입니다. Intentions은 means-ends reasoning을 드라이브하고 지속됩니다. 미래의 Deliberation을 제한하기도 하며 미래에 대한 Belief들과 연관된 녀석입니다. 좀 어렵나요? 천천히 정리해보시기 바랍니다. 다음 Means-end reasoning은 에이전트에게 달성하기 위한 목표, 수행할 수 있는 액션들, 환경의 표현을 주기 위함입니다. 목표를 달성하기 위한 계획을 생성하는 것입니다.\nReactive Agents Reactive agent는 내부적으로 세계의 표현을 매우 단순화하였으며 Perception과 Action이 매우 강하게 결속되어 있는 에이전트입니다. 행위 기반 에이전트의 전형적인 예로서 에이전트 내부에서 각 상태에 따른 Agent가 나뉘어져 있습니다.\n[ State 1 -\u0026gt; Action 1 ]\n[ State 2 -\u0026gt; Action 2 ]\nSensors -\u0026gt;[ State 3 -\u0026gt; Action 3 ] -\u0026gt;Effectors\n [ State 4 -\u0026gt; Action 4 ]\n [ State 5 -\u0026gt; Action 5 ]\n위 처럼 Sensor에서 받아들인 입력을 각 State로 전달하고 액션을 결정하여 Effector로 전달합니다. 각 행위는 지각의 입력에서 출력이 연속적으로 매핑되어 있는 구조입니다. Reactive Agents는 매우 단순하고 경제적이며 구현하기 매우 쉽습니다. 시스템 문제에 대한 강건성 또한 이 에이전트의 이점입니다. 하지만 문제도 다양합니다. 환경 모델 없는 에이전트들은 지역적 환경으로부터 가능한 충분한 정보를 가져야 합니다. 만약 지역 환경을 기반으로한 결정들은 비지역 환경들에 대해선 어떻게 고려할 것이냐도 문제가 됩니다. 또한 Reactive agents는 학습시키 매우 어렵습니다. 마지막으로 상호작용하는 요소들과 환경에 따라 동작이 달라지기 때문에 특정 에이전트를 엔지니어링 하기 어렵습니다.\nHybrid Agents Hybrid Agent는 Deliberative와 Reactive 행위의 결합입니다. 계획을 세우거나 상징적 추론을 사용해 결정을 만드는 시스템과 복잡한 추론 없이 이벤트에 대해 빠르게 반응하는 시스템이 Hybrid Agent의 서브시스템으로 구성되어 있습니다. Sensor와 Effector 사이에 Deliberative 요소와 Reactive 요소가 함께 포함되어 있습니다. Deliberative와 Reactive를 자세히 알아보았으니 Hybrid는 두개의 결합이라고 이해하면 가장 좋을 것 같습니다 :D\n잘못된 내용이나 궁금한 내용은 댓글 부탁드립니다. 긴 글 읽어주셔서 감사드립니다.\n"
},
{
	"uri": "https://linuxias.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://linuxias.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]